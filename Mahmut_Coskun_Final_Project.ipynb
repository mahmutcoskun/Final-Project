{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clap Prediction of Medium.com\n",
    "#### Term Project of Advanced Data Analytics for Management Support\n",
    "\n",
    "In this project, we will try to predict the claps of Medium.com entries by using content of entries and other suitable variables. \n",
    "We will structure different Neural Networks(NN). I devide this project into two parts. In the first phase, we will structure Natural Language Process(NLP) models by using corpuses,specifically text and headers. In the second part, we will create NN by using other(mostly numeric, categoric) variables. After all, we will combine outputs of the previous NNs to structure final NN that will give us final predictions.\n",
    "\n",
    "#### Roadmap\n",
    " - Introduction: General examining of the test and train set\n",
    " - First Step:   Structuring NLP models\n",
    " - Second Step:  Structuring models for other variables\n",
    " - Final Step:   Final Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "In this step, we will check main characteristics of train and test data. This part will let us to understand why we should combine NLP and Numeric Variables. \n",
    "First we should import necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's begin with library imports\n",
    "\n",
    "#Library used to import libraries\n",
    "import importlib\n",
    "\n",
    "#Library used for linear algebra\n",
    "import numpy as np\n",
    "\n",
    "#Library used for data structuring \n",
    "import pandas as pd\n",
    "\n",
    "#Library used for graphical representations \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Library used for working directory \n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's set our working directory.\n",
    "#os.chdir('C:\\\\Users\\\\Mahmut\\\\Desktop\\\\ADAMS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will import our test and train sets from working directory with Data Frame format as follow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = pd.read_csv('Test.csv')\n",
    "train_set = pd.read_csv('Train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Important!!!\n",
    "Before begin to analyze data, I would like to point an important approach that we will use in this task. We will use variables and text sets that are available or can be producable with existing variables both in test and train sets. At the end of the day, accuracy of our test set clap predictions are what we would like to improve and any variable that doesn't exist in test set will not help to increase accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 514 entries, 0 to 513\n",
      "Data columns (total 8 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   Unnamed: 0          514 non-null    int64 \n",
      " 1   index               514 non-null    int64 \n",
      " 2   Author              514 non-null    object\n",
      " 3   PublicationDetails  514 non-null    object\n",
      " 4   Responses           432 non-null    object\n",
      " 5   Header              506 non-null    object\n",
      " 6   Text                514 non-null    object\n",
      " 7   Length              514 non-null    int64 \n",
      "dtypes: int64(3), object(5)\n",
      "memory usage: 32.2+ KB\n"
     ]
    }
   ],
   "source": [
    "test_set.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 279577 entries, 0 to 279576\n",
      "Data columns (total 50 columns):\n",
      " #   Column                       Non-Null Count   Dtype  \n",
      "---  ------                       --------------   -----  \n",
      " 0   audioVersionDurationSec      279577 non-null  int64  \n",
      " 1   codeBlock                    25179 non-null   object \n",
      " 2   codeBlockCount               279577 non-null  float64\n",
      " 3   collectionId                 137878 non-null  object \n",
      " 4   createdDate                  279577 non-null  object \n",
      " 5   createdDatetime              279577 non-null  object \n",
      " 6   firstPublishedDate           279577 non-null  object \n",
      " 7   firstPublishedDatetime       279577 non-null  object \n",
      " 8   imageCount                   279577 non-null  int64  \n",
      " 9   isSubscriptionLocked         279577 non-null  bool   \n",
      " 10  language                     279577 non-null  object \n",
      " 11  latestPublishedDate          279577 non-null  object \n",
      " 12  latestPublishedDatetime      279577 non-null  object \n",
      " 13  linksCount                   279577 non-null  int64  \n",
      " 14  postId                       279577 non-null  object \n",
      " 15  readingTime                  279577 non-null  float64\n",
      " 16  recommends                   279577 non-null  int64  \n",
      " 17  responsesCreatedCount        279577 non-null  int64  \n",
      " 18  socialRecommendsCount        279577 non-null  int64  \n",
      " 19  subTitle                     271217 non-null  object \n",
      " 20  tagsCount                    279577 non-null  int64  \n",
      " 21  text                         279577 non-null  object \n",
      " 22  title                        279572 non-null  object \n",
      " 23  totalClapCount               279577 non-null  int64  \n",
      " 24  uniqueSlug                   279577 non-null  object \n",
      " 25  updatedDate                  279577 non-null  object \n",
      " 26  updatedDatetime              279577 non-null  object \n",
      " 27  url                          279577 non-null  object \n",
      " 28  vote                         279577 non-null  bool   \n",
      " 29  wordCount                    279577 non-null  int64  \n",
      " 30  publicationdescription       137231 non-null  object \n",
      " 31  publicationdomain            53972 non-null   object \n",
      " 32  publicationfacebookPageName  100874 non-null  object \n",
      " 33  publicationfollowerCount     0 non-null       float64\n",
      " 34  publicationname              137231 non-null  object \n",
      " 35  publicationpublicEmail       101982 non-null  object \n",
      " 36  publicationslug              137231 non-null  object \n",
      " 37  publicationtags              130298 non-null  object \n",
      " 38  publicationtwitterUsername   119851 non-null  object \n",
      " 39  tag_name                     279577 non-null  object \n",
      " 40  slug                         279577 non-null  object \n",
      " 41  name                         279577 non-null  object \n",
      " 42  postCount                    279577 non-null  float64\n",
      " 43  author                       279577 non-null  object \n",
      " 44  bio                          225480 non-null  object \n",
      " 45  userId                       279577 non-null  object \n",
      " 46  userName                     279577 non-null  object \n",
      " 47  usersFollowedByCount         279577 non-null  float64\n",
      " 48  usersFollowedCount           279577 non-null  float64\n",
      " 49  scrappedDate                 279577 non-null  int64  \n",
      "dtypes: bool(2), float64(6), int64(10), object(32)\n",
      "memory usage: 102.9+ MB\n"
     ]
    }
   ],
   "source": [
    "train_set.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>index</th>\n",
       "      <th>Author</th>\n",
       "      <th>PublicationDetails</th>\n",
       "      <th>Responses</th>\n",
       "      <th>Header</th>\n",
       "      <th>Text</th>\n",
       "      <th>Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Daniel Jeffries</td>\n",
       "      <td>Daniel Jeffries in HackerNoon.comJul 31, 2017</td>\n",
       "      <td>627 responses</td>\n",
       "      <td>Why Everyone Missed the Most Mind-Blowing Feat...</td>\n",
       "      <td>There’s one incredible feature of cryptocurren...</td>\n",
       "      <td>23401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Noam Levenson</td>\n",
       "      <td>Noam Levenson in HackerNoon.comDec 6, 2017</td>\n",
       "      <td>156 responses</td>\n",
       "      <td>NEO versus Ethereum: Why NEO might be 2018’s s...</td>\n",
       "      <td>&lt;img class=\"progressiveMedia-noscript js-progr...</td>\n",
       "      <td>23972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Daniel Jeffries</td>\n",
       "      <td>Daniel Jeffries in HackerNoon.comJul 21, 2017</td>\n",
       "      <td>176 responses</td>\n",
       "      <td>The Cryptocurrency Trading Bible</td>\n",
       "      <td>So you want to trade cryptocurrency?You’ve see...</td>\n",
       "      <td>402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>Haseeb Qureshi</td>\n",
       "      <td>Haseeb Qureshi in HackerNoon.comFeb 19, 2018</td>\n",
       "      <td>72 responses</td>\n",
       "      <td>Stablecoins: designing a price-stable cryptocu...</td>\n",
       "      <td>A useful currency should be a medium of exchan...</td>\n",
       "      <td>19730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>William Belk</td>\n",
       "      <td>William Belk in HackerNoon.comJan 28, 2018</td>\n",
       "      <td>19 responses</td>\n",
       "      <td>Chaos vs. Order — The Cryptocurrency Dilemma</td>\n",
       "      <td>Crypto crypto crypto crypto. It’s here. It’s h...</td>\n",
       "      <td>5324</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  index           Author  \\\n",
       "0           0      0  Daniel Jeffries   \n",
       "1           1      1    Noam Levenson   \n",
       "2           2      2  Daniel Jeffries   \n",
       "3           3      5   Haseeb Qureshi   \n",
       "4           4      7     William Belk   \n",
       "\n",
       "                              PublicationDetails      Responses  \\\n",
       "0  Daniel Jeffries in HackerNoon.comJul 31, 2017  627 responses   \n",
       "1     Noam Levenson in HackerNoon.comDec 6, 2017  156 responses   \n",
       "2  Daniel Jeffries in HackerNoon.comJul 21, 2017  176 responses   \n",
       "3   Haseeb Qureshi in HackerNoon.comFeb 19, 2018   72 responses   \n",
       "4     William Belk in HackerNoon.comJan 28, 2018   19 responses   \n",
       "\n",
       "                                              Header  \\\n",
       "0  Why Everyone Missed the Most Mind-Blowing Feat...   \n",
       "1  NEO versus Ethereum: Why NEO might be 2018’s s...   \n",
       "2                   The Cryptocurrency Trading Bible   \n",
       "3  Stablecoins: designing a price-stable cryptocu...   \n",
       "4       Chaos vs. Order — The Cryptocurrency Dilemma   \n",
       "\n",
       "                                                Text  Length  \n",
       "0  There’s one incredible feature of cryptocurren...   23401  \n",
       "1  <img class=\"progressiveMedia-noscript js-progr...   23972  \n",
       "2  So you want to trade cryptocurrency?You’ve see...     402  \n",
       "3  A useful currency should be a medium of exchan...   19730  \n",
       "4  Crypto crypto crypto crypto. It’s here. It’s h...    5324  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown above, we have a corpus called text. So we will structure our NLP models with respect to these column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Step: Structuring NLP Models\n",
    "In this step, we will structure an NLP model to predict clap counts.\n",
    "\n",
    "As always, we will begin with necessary library imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library re provides regular expressions functionality\n",
    "import re\n",
    "\n",
    "# To keep an eye on runtimes\n",
    "import time\n",
    "\n",
    "# Saving and loading objects\n",
    "import pickle\n",
    "\n",
    "# Library to remove html content\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Standard NLP workflow\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, we will clean, tokenize and lemmatize the content of train_set entries. In the first code block below, in this cleaning process we are following the approach as made in Tutorial 11. In the cleaning process, we add a function to remove URL contents to delete url contents in addition to html contents which are cleaned with beautifulsoup package.\n",
    "\n",
    "In the first part of the transactions, we will duplicate the text values for two reasons:\n",
    "<br> -First, having duplicates can misguide further embedding transactions. Duplicates will muniplate the relations of vectors since the relations among words will appear in each duplicated text row,\n",
    "<br> -Second, decreasing total transaction time with less content in during embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choosing text column as a list and dropping duplicates\n",
    "text=train_set['text'].copy()\n",
    "text=text.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character for lemmatization\"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "\n",
    "    return tag_dict.get(tag, wordnet.NOUN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_URL(sample):\n",
    "    return re.sub(r\"http\\S+\", \"\", sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_texts(df):\n",
    "\n",
    "    contents = []\n",
    "\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    print('*' * 40)\n",
    "    print('Cleaning {} texts.'.format(df.shape[0]))\n",
    "    counter = 0\n",
    "    for content in df:\n",
    "        \n",
    "        # remove URL/http content\n",
    "        content=remove_URL(content)\n",
    "        \n",
    "        # remove html content\n",
    "        content_text = BeautifulSoup(content).get_text()\n",
    "        \n",
    "        # remove non-alphabetic characters\n",
    "        content_text = re.sub(\"[^a-zA-Z]\",\" \", content_text)\n",
    "    \n",
    "        # tokenize the sentences\n",
    "        words = word_tokenize(content_text.lower())\n",
    "  \n",
    "        # filter stopwords\n",
    "        words = [w for w in words if w not in stopwords.words(\"english\")]\n",
    "        \n",
    "        # lemmatize each word to its lemma\n",
    "        lemma_words =[lemmatizer.lemmatize(i, get_wordnet_pos(i)) for i in words]\n",
    "    \n",
    "        contents.append(lemma_words)\n",
    "              \n",
    "        if (counter > 0 and counter % 500 == 0):\n",
    "            print('Processed {} reviews'.format(counter))\n",
    "            \n",
    "        counter += 1\n",
    "        \n",
    "    print('DONE')\n",
    "    print('*' * 40)\n",
    "\n",
    "    return(contents) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, we will apply the cleaning tokenization and lemmatization transactions that we defined above. We saved our cleaned text and integrated a code block for potential re-runs in which we can load previously cleaned text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying the cleaning,tokenization and lemmatization \n",
    "cleaned_text=clean_texts(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For saving the cleaned text\n",
    "#with open('cleaned_text.pkl','wb') as path_name:\n",
    "#   pickle.dump(cleaned_text, path_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For loading previously saved cleaned_text data \n",
    "#with open('cleaned_text.pkl','rb') as path_name:\n",
    "#    cleaned_text = pickle.load(path_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We cleaned and tokenized contents and stored them as list. We will convert tokenized values to a new data frame called __text__. In addition to tokenized values, we will add original text values into __text__ data frame to use as key value while merging with other train set contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting text list to dataframe object\n",
    "text=pd.DataFrame(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#After drop duplicates we will assign new index\n",
    "text['new_index']=range(len(text))\n",
    "text=text.set_index(text['new_index'],drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=text.drop(columns='new_index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merging cleaned text lists with text data frame\n",
    "text['cleaned_text']=''\n",
    "for i in range(len(text)):\n",
    "    text['cleaned_text'][i]=cleaned_text[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above part, we structured a dataframe, called __text__ with non-cleaned text data and clean version of it. In the below part, we will structure another dataframe that include other variables that we need during nlp process of text values.This new dataframe called __train_set_nlp__. We will combine both these dataframe with left join function by using text values in both dataframes as key Ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Structuring train_set_nlp with necessary variables for further NLP transactions\n",
    "train_set_nlp=train_set[['postId','totalClapCount','text','language']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping duplicates\n",
    "train_set_nlp=train_set_nlp.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting new indexes after drop duplicates\n",
    "train_set_nlp['new_index']=range(len(train_set_nlp))\n",
    "train_set_nlp=train_set_nlp.set_index(train_set_nlp['new_index'],drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>postId</th>\n",
       "      <th>totalClapCount</th>\n",
       "      <th>text</th>\n",
       "      <th>language</th>\n",
       "      <th>new_index</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new_index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10007d3018fe</td>\n",
       "      <td>100</td>\n",
       "      <td>Private Business, Government and Blockchain\\n\\...</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000c43bcb97</td>\n",
       "      <td>0</td>\n",
       "      <td>EPQ draft 1 (4844 words)\\nhttps://upload.wikim...</td>\n",
       "      <td>en</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100139913e4c</td>\n",
       "      <td>0</td>\n",
       "      <td>Ascent of data Science, SAS and Big data Analy...</td>\n",
       "      <td>en</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1002a55eca89</td>\n",
       "      <td>50</td>\n",
       "      <td>Can a robot love us better than another human ...</td>\n",
       "      <td>en</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10033db0a000</td>\n",
       "      <td>27</td>\n",
       "      <td>2017 Big Data, AI and IOT Use Cases\\nAn Active...</td>\n",
       "      <td>en</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72332</th>\n",
       "      <td>ffde401fb3ae</td>\n",
       "      <td>4</td>\n",
       "      <td>Analyzing extreme skiing and snowboarding in R...</td>\n",
       "      <td>en</td>\n",
       "      <td>72332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72333</th>\n",
       "      <td>ffe0bc7972b4</td>\n",
       "      <td>21</td>\n",
       "      <td>Desarrollo de una aplicación de ChatBot con Re...</td>\n",
       "      <td>es</td>\n",
       "      <td>72333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72334</th>\n",
       "      <td>ffe3f43436b8</td>\n",
       "      <td>567</td>\n",
       "      <td>How to Build a Smart Chatbot Assistant with Ch...</td>\n",
       "      <td>en</td>\n",
       "      <td>72334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72335</th>\n",
       "      <td>ffefd845665f</td>\n",
       "      <td>42</td>\n",
       "      <td>ggrepel — When Things Get Too Crowded\\nSometim...</td>\n",
       "      <td>en</td>\n",
       "      <td>72335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72336</th>\n",
       "      <td>fff8e4bd6479</td>\n",
       "      <td>0</td>\n",
       "      <td>London Creates Ethics Panel to Evaluate Use of...</td>\n",
       "      <td>en</td>\n",
       "      <td>72336</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72337 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 postId  totalClapCount  \\\n",
       "new_index                                 \n",
       "0          10007d3018fe             100   \n",
       "1          1000c43bcb97               0   \n",
       "2          100139913e4c               0   \n",
       "3          1002a55eca89              50   \n",
       "4          10033db0a000              27   \n",
       "...                 ...             ...   \n",
       "72332      ffde401fb3ae               4   \n",
       "72333      ffe0bc7972b4              21   \n",
       "72334      ffe3f43436b8             567   \n",
       "72335      ffefd845665f              42   \n",
       "72336      fff8e4bd6479               0   \n",
       "\n",
       "                                                        text language  \\\n",
       "new_index                                                               \n",
       "0          Private Business, Government and Blockchain\\n\\...       en   \n",
       "1          EPQ draft 1 (4844 words)\\nhttps://upload.wikim...       en   \n",
       "2          Ascent of data Science, SAS and Big data Analy...       en   \n",
       "3          Can a robot love us better than another human ...       en   \n",
       "4          2017 Big Data, AI and IOT Use Cases\\nAn Active...       en   \n",
       "...                                                      ...      ...   \n",
       "72332      Analyzing extreme skiing and snowboarding in R...       en   \n",
       "72333      Desarrollo de una aplicación de ChatBot con Re...       es   \n",
       "72334      How to Build a Smart Chatbot Assistant with Ch...       en   \n",
       "72335      ggrepel — When Things Get Too Crowded\\nSometim...       en   \n",
       "72336      London Creates Ethics Panel to Evaluate Use of...       en   \n",
       "\n",
       "           new_index  \n",
       "new_index             \n",
       "0                  0  \n",
       "1                  1  \n",
       "2                  2  \n",
       "3                  3  \n",
       "4                  4  \n",
       "...              ...  \n",
       "72332          72332  \n",
       "72333          72333  \n",
       "72334          72334  \n",
       "72335          72335  \n",
       "72336          72336  \n",
       "\n",
       "[72337 rows x 5 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set_nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making left join to combine our data frames \n",
    "train_set_nlp_raw=pd.merge(train_set_nlp,text,on='text',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9176493357479575"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_set_nlp_raw[train_set_nlp_raw['language']=='en'])/len(train_set_nlp_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In that part, we will make last modifications before embeddings. First of all, as shown below we checked languages of contents. Found that just c.8% of values are not in english. We will make our embeddings in gensim that doesn't support all languages. For prevention of any potential confusing issue, we will drop all non-english contents. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "en         66380\n",
       "es           890\n",
       "zh-Hant      880\n",
       "pt           873\n",
       "fr           551\n",
       "tr           378\n",
       "th           350\n",
       "ru           347\n",
       "ja           334\n",
       "it           218\n",
       "id           200\n",
       "ko           200\n",
       "zh           105\n",
       "de           102\n",
       "un            93\n",
       "vi            88\n",
       "nl            71\n",
       "sv            57\n",
       "pl            25\n",
       "cs            22\n",
       "bn            20\n",
       "no            15\n",
       "is            15\n",
       "da            13\n",
       "my            12\n",
       "uk            10\n",
       "ar            10\n",
       "mn             9\n",
       "el             8\n",
       "lo             7\n",
       "hi             6\n",
       "si             5\n",
       "la             5\n",
       "sk             4\n",
       "bg             4\n",
       "sr             3\n",
       "ro             3\n",
       "fa             3\n",
       "ka             3\n",
       "lv             2\n",
       "ms             2\n",
       "ca             2\n",
       "hu             2\n",
       "nn             2\n",
       "mk             1\n",
       "sl             1\n",
       "az             1\n",
       "mr             1\n",
       "ml             1\n",
       "lt             1\n",
       "te             1\n",
       "fi             1\n",
       "Name: language, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set_nlp_raw.language.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping non-english contents\n",
    "train_set_nlp=train_set_nlp_raw[train_set_nlp_raw['language']=='en'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "en    66380\n",
       "Name: language, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Here we have just contents in english\n",
    "train_set_nlp.language.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In addition to cleaned,tokenized list of list set ,called cleaned_text, we extract new list of list that includes just english values\n",
    "cleaned_text_en=train_set_nlp['cleaned_text'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Up until now, we have focused unigrams, so we kept all words as single values. However, we know that some values have different meanings when they come together. In our case, machine learning is a very obvious example. In spite machine and learning are totally seperate, their combination has a different meaning than both of them. So it is good idea to check bigrams in our corpuses. \n",
    "\n",
    "We trained bigram model with min count 5. In case any combination appears more than five times than the model take it into consideration as a bigram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.phrases import Phrases\n",
    "\n",
    "bigram_text_en = Phrases(cleaned_text_en,min_count=5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check, are they really important for our contents or not:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "bigram_counter = collections.Counter()\n",
    "for key in bigram_text_en.vocab.keys():\n",
    "    if key.decode().find('_')>-1: \n",
    "        bigram_counter[key] += bigram_text_en.vocab[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(b'machine_learn', 104880),\n",
       " (b'artificial_intelligence', 64671),\n",
       " (b'neural_network', 40246),\n",
       " (b'deep_learn', 38678),\n",
       " (b'data_science', 37884),\n",
       " (b'data_scientist', 21326),\n",
       " (b'big_data', 15502),\n",
       " (b'data_set', 14161),\n",
       " (b'natural_language', 11854),\n",
       " (b'real_time', 11221),\n",
       " (b'e_g', 10790),\n",
       " (b'learn_algorithm', 10541),\n",
       " (b'social_medium', 9953),\n",
       " (b'look_like', 9681),\n",
       " (b'learn_model', 9462),\n",
       " (b'use_case', 8752),\n",
       " (b'make_sure', 8700),\n",
       " (b'training_data', 8621),\n",
       " (b'decision_make', 8368),\n",
       " (b'open_source', 8309),\n",
       " (b'real_world', 7754),\n",
       " (b'reinforcement_learn', 7344),\n",
       " (b'use_ai', 7287),\n",
       " (b'language_processing', 7282),\n",
       " (b'computer_vision', 7272)]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_counter.most_common(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you check these bigrams, it is easy to realize that all these combinations have their own meanings.Furthermore, numbers in the tuples show that authors use these terms frequently so they have significant impacts in the corpuses. Because of all these reasons, we decided to chance suitable unigrams with bigrams in our cleaned text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_bigram_text_en=[]\n",
    "for i in range(len(cleaned_text_en)):\n",
    "    cleaned_bigram_text_en.append(bigram_text_en[cleaned_text_en[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we completed all previous transactions to train our embeddings. \n",
    "\n",
    " - We will make embedding with embedding dimension of 200. We know the industry standarts between 100 to 300. We decided the middle point to make this transaction faster but not weak.\n",
    " - As in our bigram transaction, our minimum count parameter is five. So we will consider the words that appear at least five times in our cleaned text.\n",
    " - We would like to make these transaction as fast as possible so we will run a multiprocessing code to find out how many cores our computer have and will use all of them to make paralel transactions simultaneously.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "\n",
    "cores=multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "emb_dim=200\n",
    "model_bigram = Word2Vec(cleaned_bigram_text_en, \n",
    "                         min_count=5,  \n",
    "                         window=5,     \n",
    "                         iter=100,     \n",
    "                         size=emb_dim, \n",
    "                         workers=cores) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "words=list(model_bigram.wv.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we made embeddings and saved with word2vec format. We named it as model_index and we will use it in pre-trained embeddings model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "from gensim.models.keyedvectors import Word2VecKeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "embs=\"en_bigram_embeddings.model\"\n",
    "save_as_bin = False\n",
    "#model_bigram.wv.save_word2vec_format(embs, binary=save_as_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_index = KeyedVectors.load_word2vec_format(embs, binary=save_as_bin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We structured our content data for NLP means that we did all transactions for x variable. So it is time to focus y variable which is totalClapCount. Lets make an histogram to check its distribution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x21dd2c63908>"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_set_nlp['totalClapCount'].hist(bins=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As observed above, distribution of the clap counts is very far from an ideal normal distribution. For this kind of problems, one of the ways is implementing logarithmic transformation. While implementing logarithmic transformation we will add one to all clap counts since we have values as 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Log-transformed clap counts stored in a new columns called transform\n",
    "train_set_nlp['transform']=np.log(train_set_nlp['totalClapCount']+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x21ddbef9b08>"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_set_nlp['transform'].hist(bins=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We tokenized contexts to train them. Now it is done so we will detokenize cleaned text and will use it for our sentiment analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "\n",
    "train_set_nlp['cleaned_bi_text'] = [TreebankWordDetokenizer().detokenize(text) for text in cleaned_bigram_text_en]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 66380 entries, 0 to 66379\n",
      "Data columns (total 7 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   postId           66380 non-null  object \n",
      " 1   totalClapCount   66380 non-null  int64  \n",
      " 2   text             66380 non-null  object \n",
      " 3   language         66380 non-null  object \n",
      " 4   cleaned_text     66380 non-null  object \n",
      " 5   transform        66380 non-null  float64\n",
      " 6   cleaned_bi_text  66380 non-null  object \n",
      "dtypes: float64(1), int64(1), object(5)\n",
      "memory usage: 4.1+ MB\n"
     ]
    }
   ],
   "source": [
    "train_set_nlp.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All transactions are done for nlp modelling. We will get x and y variables into a new dataframe to decrease memory usage. As shown above it is aroun 7.3 now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_nlp_model=train_set_nlp[['cleaned_bi_text','transform']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 66380 entries, 0 to 66379\n",
      "Data columns (total 2 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   cleaned_bi_text  66380 non-null  object \n",
      " 1   transform        66380 non-null  float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "train_nlp_model.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We kept just final necessary input and output that led to decrease memory usage to 1.5 MB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For replicability we will keep seed always same which is as follow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "seed(1)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will not split our data into train and test because during the application of models we already using validation sets to test our trainings. In addition to that our test set is already something splitted that we will apply at the end of all tasks. Furthermore, we would like to keep train set as big as possible to make more accurate training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=train_nlp_model['cleaned_bi_text'] \n",
    "Y_train=train_nlp_model['transform']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "NUM_WORDS = 10000   \n",
    "\n",
    "tokenizer_obj = Tokenizer(NUM_WORDS, oov_token=1)  \n",
    "tokenizer_obj.fit_on_texts(X_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr_int = tokenizer_obj.texts_to_sequences(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For deciding max review of length, we checked the length of tokenized contents list. We can see from percentiles that this value is explonantial. So we gave a proper length to exceeds most of the contents length but not big to save computer performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    66380.000000\n",
       "mean       505.940343\n",
       "std        462.500418\n",
       "min          0.000000\n",
       "25%        235.000000\n",
       "50%        400.000000\n",
       "75%        635.000000\n",
       "max      12918.000000\n",
       "Name: Length_list, dtype: float64"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set_nlp['Length_list'] = train_set_nlp.cleaned_text.apply(lambda x: len(x))\n",
    "train_set_nlp['Length_list'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_REVIEW_LENGTH = 1000\n",
    "\n",
    "X_tr_int_pad = pad_sequences(X_tr_int, MAX_REVIEW_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding,GRU, Dropout\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.initializers import Constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_HIDDEN = 16\n",
    "EPOCH = 3\n",
    "BATCH_SIZE = 64 \n",
    "EMBEDDING_DIM = 200\n",
    "VAL_SPLIT = 0.25  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get embedding weights by using following transactions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding_matrix(tokenizer, pretrain, vocab_size):\n",
    "  \n",
    "    dim = 0\n",
    "    if isinstance(pretrain, KeyedVectors) or isinstance(pretrain, Word2VecKeyedVectors):\n",
    "        dim = pretrain.vector_size        \n",
    "    elif isinstance(pretrain, dict):\n",
    "        dim = next(iter(pretrain.values())).shape[0]  \n",
    "    else:\n",
    "        raise Exception('{} is not supported'.format(type(pretrain)))\n",
    "    \n",
    "    \n",
    "    \n",
    "    emb_mat = np.zeros((vocab_size, dim))\n",
    "\n",
    "    \n",
    "    oov_words = []\n",
    "\n",
    "    for word, i in tokenizer.word_index.items():  \n",
    "       \n",
    "        try:\n",
    "            emb_mat[i] = pretrain[word]\n",
    "        except:\n",
    "            oov_words.append(word)\n",
    "    print('Created embedding matrix of shape {}'.format(emb_mat.shape))\n",
    "    print('Encountered {} out-of-vocabulary words.'.format(len(oov_words)))\n",
    "    return (emb_mat, oov_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created embedding matrix of shape (10000, 200)\n",
      "Encountered 202387 out-of-vocabulary words.\n"
     ]
    }
   ],
   "source": [
    "embs_weights, _ = get_embedding_matrix(tokenizer_obj,model_index, NUM_WORDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will structure some models for NLP. Mainly we have three models. In the first one, we are using pre-trained weights. In the second one, we are not using pre_trained weihts. In last model, we are using pre-trained weights but the difference is it is training itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 1000, 200)         2000000   \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 16)                10416     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 2,010,433\n",
      "Trainable params: 10,433\n",
      "Non-trainable params: 2,000,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding_layer=Embedding(input_dim=NUM_WORDS, \n",
    "                          output_dim=EMBEDDING_DIM, \n",
    "                          input_length=MAX_REVIEW_LENGTH,\n",
    "                          embeddings_initializer=Constant(embs_weights), \n",
    "                          trainable=False  \n",
    "                         )\n",
    "\n",
    "model1=Sequential()                        \n",
    "model1.add(embedding_layer)\n",
    "model1.add(GRU(NB_HIDDEN))\n",
    "model1.add(Dense(1, activation=\"sigmoid\"))\n",
    "model1.compile(loss=\"MSE\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 49785 samples, validate on 16595 samples\n",
      "Epoch 1/3\n",
      "49785/49785 [==============================] - 325s 7ms/step - loss: 5.3981 - accuracy: 0.0030 - val_loss: 11.9979 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/3\n",
      "49785/49785 [==============================] - 328s 7ms/step - loss: 5.3644 - accuracy: 0.0020 - val_loss: 11.9935 - val_accuracy: 0.0019\n",
      "Epoch 3/3\n",
      "49785/49785 [==============================] - 328s 7ms/step - loss: 5.3612 - accuracy: 0.0052 - val_loss: 11.9922 - val_accuracy: 0.0020\n"
     ]
    }
   ],
   "source": [
    "model1_story = model1.fit(X_tr_int_pad, Y_train, batch_size=BATCH_SIZE, epochs=EPOCH, validation_split=VAL_SPLIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 1000, 200)         2000000   \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (None, 16)                10416     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 2,010,433\n",
      "Trainable params: 2,010,433\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Embedding layer\n",
    "embedding_layer=Embedding(input_dim=NUM_WORDS, \n",
    "                          output_dim=EMBEDDING_DIM, \n",
    "                          input_length=MAX_REVIEW_LENGTH\n",
    "                         )\n",
    "# GRU text classifier\n",
    "model2=Sequential()                        \n",
    "model2.add(embedding_layer)\n",
    "model2.add(GRU(NB_HIDDEN))\n",
    "model2.add(Dense(1, activation=\"sigmoid\"))\n",
    "model2.compile(loss=\"MSE\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 49785 samples, validate on 16595 samples\n",
      "Epoch 1/3\n",
      "49785/49785 [==============================] - 386s 8ms/step - loss: 5.3815 - accuracy: 0.0146 - val_loss: 12.0016 - val_accuracy: 0.0048\n",
      "Epoch 2/3\n",
      "49785/49785 [==============================] - 401s 8ms/step - loss: 5.3442 - accuracy: 0.0262 - val_loss: 12.0564 - val_accuracy: 0.0098\n",
      "Epoch 3/3\n",
      "49785/49785 [==============================] - 384s 8ms/step - loss: 5.3201 - accuracy: 0.0533 - val_loss: 12.0633 - val_accuracy: 0.0114\n"
     ]
    }
   ],
   "source": [
    "model2_story = model2.fit(X_tr_int_pad, Y_train, batch_size=BATCH_SIZE, epochs=EPOCH, validation_split=VAL_SPLIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "GRUw = model1.layers[1].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 1000, 200)         2000000   \n",
      "_________________________________________________________________\n",
      "gru_4 (GRU)                  (None, 16)                10416     \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 2,010,433\n",
      "Trainable params: 2,010,433\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3=Sequential()\n",
    "embedding_layer=Embedding(NUM_WORDS, \n",
    "                         EMBEDDING_DIM,  \n",
    "                         embeddings_initializer=Constant(embs_weights), \n",
    "                         input_length=MAX_REVIEW_LENGTH, \n",
    "                         trainable=True  \n",
    "                         )\n",
    "model3.add(embedding_layer)\n",
    "\n",
    "model3.add(GRU(NB_HIDDEN, weights=GRUw))\n",
    "model3.add(Dense(1, activation=\"sigmoid\"))\n",
    "model3.compile(loss=\"MSE\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3_story = model3.fit(X_tr_int_pad, Y_train, batch_size=BATCH_SIZE, epochs=EPOCH, validation_split=VAL_SPLIT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We tried all these three models and according to losses the second one is the best to use as NLP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second Step: Structuring Models from Other Variables\n",
    "In this step, we will try to extract variables that are both appear in text and train sets. We know that train set is really rich about number of variables. However, there are just couple of variables appear in test set because of this reason we will begin by analyzing our test set to see which variables are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>index</th>\n",
       "      <th>Author</th>\n",
       "      <th>PublicationDetails</th>\n",
       "      <th>Responses</th>\n",
       "      <th>Header</th>\n",
       "      <th>Text</th>\n",
       "      <th>Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Daniel Jeffries</td>\n",
       "      <td>Daniel Jeffries in HackerNoon.comJul 31, 2017</td>\n",
       "      <td>627 responses</td>\n",
       "      <td>Why Everyone Missed the Most Mind-Blowing Feat...</td>\n",
       "      <td>There’s one incredible feature of cryptocurren...</td>\n",
       "      <td>23401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Noam Levenson</td>\n",
       "      <td>Noam Levenson in HackerNoon.comDec 6, 2017</td>\n",
       "      <td>156 responses</td>\n",
       "      <td>NEO versus Ethereum: Why NEO might be 2018’s s...</td>\n",
       "      <td>&lt;img class=\"progressiveMedia-noscript js-progr...</td>\n",
       "      <td>23972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Daniel Jeffries</td>\n",
       "      <td>Daniel Jeffries in HackerNoon.comJul 21, 2017</td>\n",
       "      <td>176 responses</td>\n",
       "      <td>The Cryptocurrency Trading Bible</td>\n",
       "      <td>So you want to trade cryptocurrency?You’ve see...</td>\n",
       "      <td>402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>Haseeb Qureshi</td>\n",
       "      <td>Haseeb Qureshi in HackerNoon.comFeb 19, 2018</td>\n",
       "      <td>72 responses</td>\n",
       "      <td>Stablecoins: designing a price-stable cryptocu...</td>\n",
       "      <td>A useful currency should be a medium of exchan...</td>\n",
       "      <td>19730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>William Belk</td>\n",
       "      <td>William Belk in HackerNoon.comJan 28, 2018</td>\n",
       "      <td>19 responses</td>\n",
       "      <td>Chaos vs. Order — The Cryptocurrency Dilemma</td>\n",
       "      <td>Crypto crypto crypto crypto. It’s here. It’s h...</td>\n",
       "      <td>5324</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  index           Author  \\\n",
       "0           0      0  Daniel Jeffries   \n",
       "1           1      1    Noam Levenson   \n",
       "2           2      2  Daniel Jeffries   \n",
       "3           3      5   Haseeb Qureshi   \n",
       "4           4      7     William Belk   \n",
       "\n",
       "                              PublicationDetails      Responses  \\\n",
       "0  Daniel Jeffries in HackerNoon.comJul 31, 2017  627 responses   \n",
       "1     Noam Levenson in HackerNoon.comDec 6, 2017  156 responses   \n",
       "2  Daniel Jeffries in HackerNoon.comJul 21, 2017  176 responses   \n",
       "3   Haseeb Qureshi in HackerNoon.comFeb 19, 2018   72 responses   \n",
       "4     William Belk in HackerNoon.comJan 28, 2018   19 responses   \n",
       "\n",
       "                                              Header  \\\n",
       "0  Why Everyone Missed the Most Mind-Blowing Feat...   \n",
       "1  NEO versus Ethereum: Why NEO might be 2018’s s...   \n",
       "2                   The Cryptocurrency Trading Bible   \n",
       "3  Stablecoins: designing a price-stable cryptocu...   \n",
       "4       Chaos vs. Order — The Cryptocurrency Dilemma   \n",
       "\n",
       "                                                Text  Length  \n",
       "0  There’s one incredible feature of cryptocurren...   23401  \n",
       "1  <img class=\"progressiveMedia-noscript js-progr...   23972  \n",
       "2  So you want to trade cryptocurrency?You’ve see...     402  \n",
       "3  A useful currency should be a medium of exchan...   19730  \n",
       "4  Crypto crypto crypto crypto. It’s here. It’s h...    5324  "
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the details of variables.\n",
    "\n",
    "Publication Details is the first one since it covers more than one variable so we can split it into groups. We split Publication Details as follow:\n",
    "<br>\n",
    "<br>First we will identify months since it is a good approach to split date part first and remaining part after it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "months=('Jan ','Feb ','Mar ','Apr ','May ','Jun ','Jul ','Aug ','Sep ','Oct ','Nov ','Dec ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = {}\n",
    "publisher={}\n",
    "for month in months:\n",
    "    for i in range(len(test_set['PublicationDetails'])):\n",
    "        if month in test_set['PublicationDetails'][i]:\n",
    "            text=test_set['PublicationDetails'][i]\n",
    "            test_index=test_set['index'][i]\n",
    "            posit=text.find(month)\n",
    "            date[test_index]=text[posit:]\n",
    "            publisher[test_index]=text[:posit]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "date = collections.OrderedDict(sorted(date.items()))\n",
    "publisher = collections.OrderedDict(sorted(publisher.items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We extracted Publish Date as PublishDate and remainings as Publisher. However, remaining part consist of more than one variable. These variables are author name and website both can be splitted with 'in'. We will do these transactions and integrate them to dataframe in next two code blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set['PublishDate']=pd.DataFrame(list(date.values()))\n",
    "test_set['Publisher']=pd.DataFrame(list(publisher.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "devided=test_set['Publisher'].str.split(' in ',n=1,expand=True)\n",
    "test_set['Extracted Author']=devided[0]\n",
    "test_set['WebSite']=devided[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>index</th>\n",
       "      <th>Author</th>\n",
       "      <th>PublicationDetails</th>\n",
       "      <th>Responses</th>\n",
       "      <th>Header</th>\n",
       "      <th>Text</th>\n",
       "      <th>Length</th>\n",
       "      <th>PublishDate</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Extracted Author</th>\n",
       "      <th>WebSite</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Daniel Jeffries</td>\n",
       "      <td>Daniel Jeffries in HackerNoon.comJul 31, 2017</td>\n",
       "      <td>627 responses</td>\n",
       "      <td>Why Everyone Missed the Most Mind-Blowing Feat...</td>\n",
       "      <td>There’s one incredible feature of cryptocurren...</td>\n",
       "      <td>23401</td>\n",
       "      <td>Jul 31, 2017</td>\n",
       "      <td>Daniel Jeffries in HackerNoon.com</td>\n",
       "      <td>Daniel Jeffries</td>\n",
       "      <td>HackerNoon.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Noam Levenson</td>\n",
       "      <td>Noam Levenson in HackerNoon.comDec 6, 2017</td>\n",
       "      <td>156 responses</td>\n",
       "      <td>NEO versus Ethereum: Why NEO might be 2018’s s...</td>\n",
       "      <td>&lt;img class=\"progressiveMedia-noscript js-progr...</td>\n",
       "      <td>23972</td>\n",
       "      <td>Dec 6, 2017</td>\n",
       "      <td>Noam Levenson in HackerNoon.com</td>\n",
       "      <td>Noam Levenson</td>\n",
       "      <td>HackerNoon.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Daniel Jeffries</td>\n",
       "      <td>Daniel Jeffries in HackerNoon.comJul 21, 2017</td>\n",
       "      <td>176 responses</td>\n",
       "      <td>The Cryptocurrency Trading Bible</td>\n",
       "      <td>So you want to trade cryptocurrency?You’ve see...</td>\n",
       "      <td>402</td>\n",
       "      <td>Jul 21, 2017</td>\n",
       "      <td>Daniel Jeffries in HackerNoon.com</td>\n",
       "      <td>Daniel Jeffries</td>\n",
       "      <td>HackerNoon.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>Haseeb Qureshi</td>\n",
       "      <td>Haseeb Qureshi in HackerNoon.comFeb 19, 2018</td>\n",
       "      <td>72 responses</td>\n",
       "      <td>Stablecoins: designing a price-stable cryptocu...</td>\n",
       "      <td>A useful currency should be a medium of exchan...</td>\n",
       "      <td>19730</td>\n",
       "      <td>Feb 19, 2018</td>\n",
       "      <td>Haseeb Qureshi in HackerNoon.com</td>\n",
       "      <td>Haseeb Qureshi</td>\n",
       "      <td>HackerNoon.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>William Belk</td>\n",
       "      <td>William Belk in HackerNoon.comJan 28, 2018</td>\n",
       "      <td>19 responses</td>\n",
       "      <td>Chaos vs. Order — The Cryptocurrency Dilemma</td>\n",
       "      <td>Crypto crypto crypto crypto. It’s here. It’s h...</td>\n",
       "      <td>5324</td>\n",
       "      <td>Jan 28, 2018</td>\n",
       "      <td>William Belk in HackerNoon.com</td>\n",
       "      <td>William Belk</td>\n",
       "      <td>HackerNoon.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>509</td>\n",
       "      <td>598</td>\n",
       "      <td>Jun 9, 2016</td>\n",
       "      <td>Tim Romero in Startup Lessons LearnedJun 9, 2016</td>\n",
       "      <td>181 responses</td>\n",
       "      <td>Why I turned down $500K, Pissed off my investo...</td>\n",
       "      <td>I just did what no startup founder is ever sup...</td>\n",
       "      <td>9025</td>\n",
       "      <td>Jun 9, 2016</td>\n",
       "      <td>Tim Romero in Startup Lessons Learned</td>\n",
       "      <td>Tim Romero</td>\n",
       "      <td>Startup Lessons Learned</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>510</td>\n",
       "      <td>599</td>\n",
       "      <td>Jun 10, 2016</td>\n",
       "      <td>Product HuntJun 10, 2016</td>\n",
       "      <td>24 responses</td>\n",
       "      <td>These Tools Will Help You Launch Your Startup</td>\n",
       "      <td>If you’re embarking on the startup journey and...</td>\n",
       "      <td>5571</td>\n",
       "      <td>Jun 10, 2016</td>\n",
       "      <td>Product Hunt</td>\n",
       "      <td>Product Hunt</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>511</td>\n",
       "      <td>600</td>\n",
       "      <td>Mar-19</td>\n",
       "      <td>Joe ProcopioMar 19</td>\n",
       "      <td>24 responses</td>\n",
       "      <td>Why Startups Fall Apart at 50 Employees</td>\n",
       "      <td>Fuck you startups with your extravagant partie...</td>\n",
       "      <td>475</td>\n",
       "      <td>Mar 19</td>\n",
       "      <td>Joe Procopio</td>\n",
       "      <td>Joe Procopio</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>512</td>\n",
       "      <td>601</td>\n",
       "      <td>Mar 18, 2016</td>\n",
       "      <td>Winerist in Be YourselfMar 18, 2016</td>\n",
       "      <td>116 responses</td>\n",
       "      <td>Beware of Startup Prostitution</td>\n",
       "      <td>Note: This is not a post to glorify prostituti...</td>\n",
       "      <td>13483</td>\n",
       "      <td>Mar 18, 2016</td>\n",
       "      <td>Winerist in Be Yourself</td>\n",
       "      <td>Winerist</td>\n",
       "      <td>Be Yourself</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>513</td>\n",
       "      <td>602</td>\n",
       "      <td>Jan 11, 2018</td>\n",
       "      <td>Aytekin Tank in The StartupJan 11, 2018</td>\n",
       "      <td>34 responses</td>\n",
       "      <td>How to build a startup — without quitting your...</td>\n",
       "      <td>Question: What do Craigslist and Albert Einste...</td>\n",
       "      <td>8736</td>\n",
       "      <td>Jan 11, 2018</td>\n",
       "      <td>Aytekin Tank in The Startup</td>\n",
       "      <td>Aytekin Tank</td>\n",
       "      <td>The Startup</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>514 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  index           Author  \\\n",
       "0             0      0  Daniel Jeffries   \n",
       "1             1      1    Noam Levenson   \n",
       "2             2      2  Daniel Jeffries   \n",
       "3             3      5   Haseeb Qureshi   \n",
       "4             4      7     William Belk   \n",
       "..          ...    ...              ...   \n",
       "509         509    598      Jun 9, 2016   \n",
       "510         510    599     Jun 10, 2016   \n",
       "511         511    600           Mar-19   \n",
       "512         512    601     Mar 18, 2016   \n",
       "513         513    602     Jan 11, 2018   \n",
       "\n",
       "                                   PublicationDetails      Responses  \\\n",
       "0       Daniel Jeffries in HackerNoon.comJul 31, 2017  627 responses   \n",
       "1          Noam Levenson in HackerNoon.comDec 6, 2017  156 responses   \n",
       "2       Daniel Jeffries in HackerNoon.comJul 21, 2017  176 responses   \n",
       "3        Haseeb Qureshi in HackerNoon.comFeb 19, 2018   72 responses   \n",
       "4          William Belk in HackerNoon.comJan 28, 2018   19 responses   \n",
       "..                                                ...            ...   \n",
       "509  Tim Romero in Startup Lessons LearnedJun 9, 2016  181 responses   \n",
       "510                          Product HuntJun 10, 2016   24 responses   \n",
       "511                                Joe ProcopioMar 19   24 responses   \n",
       "512               Winerist in Be YourselfMar 18, 2016  116 responses   \n",
       "513           Aytekin Tank in The StartupJan 11, 2018   34 responses   \n",
       "\n",
       "                                                Header  \\\n",
       "0    Why Everyone Missed the Most Mind-Blowing Feat...   \n",
       "1    NEO versus Ethereum: Why NEO might be 2018’s s...   \n",
       "2                     The Cryptocurrency Trading Bible   \n",
       "3    Stablecoins: designing a price-stable cryptocu...   \n",
       "4         Chaos vs. Order — The Cryptocurrency Dilemma   \n",
       "..                                                 ...   \n",
       "509  Why I turned down $500K, Pissed off my investo...   \n",
       "510      These Tools Will Help You Launch Your Startup   \n",
       "511            Why Startups Fall Apart at 50 Employees   \n",
       "512                     Beware of Startup Prostitution   \n",
       "513  How to build a startup — without quitting your...   \n",
       "\n",
       "                                                  Text  Length   PublishDate  \\\n",
       "0    There’s one incredible feature of cryptocurren...   23401  Jul 31, 2017   \n",
       "1    <img class=\"progressiveMedia-noscript js-progr...   23972   Dec 6, 2017   \n",
       "2    So you want to trade cryptocurrency?You’ve see...     402  Jul 21, 2017   \n",
       "3    A useful currency should be a medium of exchan...   19730  Feb 19, 2018   \n",
       "4    Crypto crypto crypto crypto. It’s here. It’s h...    5324  Jan 28, 2018   \n",
       "..                                                 ...     ...           ...   \n",
       "509  I just did what no startup founder is ever sup...    9025   Jun 9, 2016   \n",
       "510  If you’re embarking on the startup journey and...    5571  Jun 10, 2016   \n",
       "511  Fuck you startups with your extravagant partie...     475        Mar 19   \n",
       "512  Note: This is not a post to glorify prostituti...   13483  Mar 18, 2016   \n",
       "513  Question: What do Craigslist and Albert Einste...    8736  Jan 11, 2018   \n",
       "\n",
       "                                 Publisher Extracted Author  \\\n",
       "0        Daniel Jeffries in HackerNoon.com  Daniel Jeffries   \n",
       "1          Noam Levenson in HackerNoon.com    Noam Levenson   \n",
       "2        Daniel Jeffries in HackerNoon.com  Daniel Jeffries   \n",
       "3         Haseeb Qureshi in HackerNoon.com   Haseeb Qureshi   \n",
       "4           William Belk in HackerNoon.com     William Belk   \n",
       "..                                     ...              ...   \n",
       "509  Tim Romero in Startup Lessons Learned       Tim Romero   \n",
       "510                           Product Hunt     Product Hunt   \n",
       "511                           Joe Procopio     Joe Procopio   \n",
       "512                Winerist in Be Yourself         Winerist   \n",
       "513            Aytekin Tank in The Startup     Aytekin Tank   \n",
       "\n",
       "                     WebSite  \n",
       "0             HackerNoon.com  \n",
       "1             HackerNoon.com  \n",
       "2             HackerNoon.com  \n",
       "3             HackerNoon.com  \n",
       "4             HackerNoon.com  \n",
       "..                       ...  \n",
       "509  Startup Lessons Learned  \n",
       "510                     None  \n",
       "511                     None  \n",
       "512              Be Yourself  \n",
       "513              The Startup  \n",
       "\n",
       "[514 rows x 12 columns]"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set[:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown above, we have two variables Author and Extracted Author. Author variable is not very well structured column. You can easily obsorve at last lines above. On the other hand, our extracted author variable is more proper to use. This is why we will switch Author and Extracted Author then we will drop Extracted Author, PublicationDetails and Publisher variables since they are used during the process and not necessary anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set['Author']=test_set['Extracted Author']\n",
    "test_set=test_set.drop(columns=['PublicationDetails','Extracted Author','Publisher'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this group of data, we can use Author as an input but first we have to check we have all these Authors in data set. At the end of the day, if we would like to use Authors as categoric variables or embedded variables. In any case their values have to be trained in train set and all they are not appear in train set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have an important variable that we can use to see total number of days since publication day of the content.\n",
    "We don't know the scrapping time of the test set so we can assumed that both train and test sets scrapping times are same. We know exact scrapping time of the training set and we checked that it is not later then the latest publish date in test set. So we can use scrapping time of train set for test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sep 7, 2018'"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(test_set.PublishDate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set2=test_set.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mahmut\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(test_set['PublishDate'])):\n",
    "    x=test_set['PublishDate'][i]\n",
    "    if len(x)<7:\n",
    "        test_set['PublishDate'][i]=x+', 2017'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mahmut\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "for i in range(len(test_set['PublishDate'])):\n",
    "    test_set['PublishDate'][i]=datetime.strptime(test_set['PublishDate'][i],\"%b %d, %Y\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set['scrappedDate']=pd.to_datetime(test_set['scrappedDate']).apply(lambda x: x.date())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set['PublishDate']=pd.to_datetime(test_set['PublishDate']).apply(lambda x: x.date())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set['PublishedDay']=test_set['scrappedDate']-test_set['PublishDate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set2=test_set.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set2['PublishedDay'] = test_set2['PublishedDay'].dt.days.astype('int16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>index</th>\n",
       "      <th>Author</th>\n",
       "      <th>Responses</th>\n",
       "      <th>Header</th>\n",
       "      <th>Text</th>\n",
       "      <th>Length</th>\n",
       "      <th>PublishDate</th>\n",
       "      <th>WebSite</th>\n",
       "      <th>scrappedDate</th>\n",
       "      <th>PublishedDay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Daniel Jeffries</td>\n",
       "      <td>627 responses</td>\n",
       "      <td>Why Everyone Missed the Most Mind-Blowing Feat...</td>\n",
       "      <td>There’s one incredible feature of cryptocurren...</td>\n",
       "      <td>23401</td>\n",
       "      <td>2017-07-31</td>\n",
       "      <td>HackerNoon.com</td>\n",
       "      <td>2018-11-04</td>\n",
       "      <td>461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Noam Levenson</td>\n",
       "      <td>156 responses</td>\n",
       "      <td>NEO versus Ethereum: Why NEO might be 2018’s s...</td>\n",
       "      <td>&lt;img class=\"progressiveMedia-noscript js-progr...</td>\n",
       "      <td>23972</td>\n",
       "      <td>2017-12-06</td>\n",
       "      <td>HackerNoon.com</td>\n",
       "      <td>2018-11-04</td>\n",
       "      <td>333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Daniel Jeffries</td>\n",
       "      <td>176 responses</td>\n",
       "      <td>The Cryptocurrency Trading Bible</td>\n",
       "      <td>So you want to trade cryptocurrency?You’ve see...</td>\n",
       "      <td>402</td>\n",
       "      <td>2017-07-21</td>\n",
       "      <td>HackerNoon.com</td>\n",
       "      <td>2018-11-04</td>\n",
       "      <td>471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>Haseeb Qureshi</td>\n",
       "      <td>72 responses</td>\n",
       "      <td>Stablecoins: designing a price-stable cryptocu...</td>\n",
       "      <td>A useful currency should be a medium of exchan...</td>\n",
       "      <td>19730</td>\n",
       "      <td>2018-02-19</td>\n",
       "      <td>HackerNoon.com</td>\n",
       "      <td>2018-11-04</td>\n",
       "      <td>258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>William Belk</td>\n",
       "      <td>19 responses</td>\n",
       "      <td>Chaos vs. Order — The Cryptocurrency Dilemma</td>\n",
       "      <td>Crypto crypto crypto crypto. It’s here. It’s h...</td>\n",
       "      <td>5324</td>\n",
       "      <td>2018-01-28</td>\n",
       "      <td>HackerNoon.com</td>\n",
       "      <td>2018-11-04</td>\n",
       "      <td>280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>509</td>\n",
       "      <td>598</td>\n",
       "      <td>Tim Romero</td>\n",
       "      <td>181 responses</td>\n",
       "      <td>Why I turned down $500K, Pissed off my investo...</td>\n",
       "      <td>I just did what no startup founder is ever sup...</td>\n",
       "      <td>9025</td>\n",
       "      <td>2016-06-09</td>\n",
       "      <td>Startup Lessons Learned</td>\n",
       "      <td>2018-11-04</td>\n",
       "      <td>878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>510</td>\n",
       "      <td>599</td>\n",
       "      <td>Product Hunt</td>\n",
       "      <td>24 responses</td>\n",
       "      <td>These Tools Will Help You Launch Your Startup</td>\n",
       "      <td>If you’re embarking on the startup journey and...</td>\n",
       "      <td>5571</td>\n",
       "      <td>2016-06-10</td>\n",
       "      <td>None</td>\n",
       "      <td>2018-11-04</td>\n",
       "      <td>877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>511</td>\n",
       "      <td>600</td>\n",
       "      <td>Joe Procopio</td>\n",
       "      <td>24 responses</td>\n",
       "      <td>Why Startups Fall Apart at 50 Employees</td>\n",
       "      <td>Fuck you startups with your extravagant partie...</td>\n",
       "      <td>475</td>\n",
       "      <td>2017-03-19</td>\n",
       "      <td>None</td>\n",
       "      <td>2018-11-04</td>\n",
       "      <td>595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>512</td>\n",
       "      <td>601</td>\n",
       "      <td>Winerist</td>\n",
       "      <td>116 responses</td>\n",
       "      <td>Beware of Startup Prostitution</td>\n",
       "      <td>Note: This is not a post to glorify prostituti...</td>\n",
       "      <td>13483</td>\n",
       "      <td>2016-03-18</td>\n",
       "      <td>Be Yourself</td>\n",
       "      <td>2018-11-04</td>\n",
       "      <td>961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>513</td>\n",
       "      <td>602</td>\n",
       "      <td>Aytekin Tank</td>\n",
       "      <td>34 responses</td>\n",
       "      <td>How to build a startup — without quitting your...</td>\n",
       "      <td>Question: What do Craigslist and Albert Einste...</td>\n",
       "      <td>8736</td>\n",
       "      <td>2018-01-11</td>\n",
       "      <td>The Startup</td>\n",
       "      <td>2018-11-04</td>\n",
       "      <td>297</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>514 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  index           Author      Responses  \\\n",
       "0             0      0  Daniel Jeffries  627 responses   \n",
       "1             1      1    Noam Levenson  156 responses   \n",
       "2             2      2  Daniel Jeffries  176 responses   \n",
       "3             3      5   Haseeb Qureshi   72 responses   \n",
       "4             4      7     William Belk   19 responses   \n",
       "..          ...    ...              ...            ...   \n",
       "509         509    598       Tim Romero  181 responses   \n",
       "510         510    599     Product Hunt   24 responses   \n",
       "511         511    600     Joe Procopio   24 responses   \n",
       "512         512    601         Winerist  116 responses   \n",
       "513         513    602     Aytekin Tank   34 responses   \n",
       "\n",
       "                                                Header  \\\n",
       "0    Why Everyone Missed the Most Mind-Blowing Feat...   \n",
       "1    NEO versus Ethereum: Why NEO might be 2018’s s...   \n",
       "2                     The Cryptocurrency Trading Bible   \n",
       "3    Stablecoins: designing a price-stable cryptocu...   \n",
       "4         Chaos vs. Order — The Cryptocurrency Dilemma   \n",
       "..                                                 ...   \n",
       "509  Why I turned down $500K, Pissed off my investo...   \n",
       "510      These Tools Will Help You Launch Your Startup   \n",
       "511            Why Startups Fall Apart at 50 Employees   \n",
       "512                     Beware of Startup Prostitution   \n",
       "513  How to build a startup — without quitting your...   \n",
       "\n",
       "                                                  Text  Length PublishDate  \\\n",
       "0    There’s one incredible feature of cryptocurren...   23401  2017-07-31   \n",
       "1    <img class=\"progressiveMedia-noscript js-progr...   23972  2017-12-06   \n",
       "2    So you want to trade cryptocurrency?You’ve see...     402  2017-07-21   \n",
       "3    A useful currency should be a medium of exchan...   19730  2018-02-19   \n",
       "4    Crypto crypto crypto crypto. It’s here. It’s h...    5324  2018-01-28   \n",
       "..                                                 ...     ...         ...   \n",
       "509  I just did what no startup founder is ever sup...    9025  2016-06-09   \n",
       "510  If you’re embarking on the startup journey and...    5571  2016-06-10   \n",
       "511  Fuck you startups with your extravagant partie...     475  2017-03-19   \n",
       "512  Note: This is not a post to glorify prostituti...   13483  2016-03-18   \n",
       "513  Question: What do Craigslist and Albert Einste...    8736  2018-01-11   \n",
       "\n",
       "                     WebSite scrappedDate  PublishedDay  \n",
       "0             HackerNoon.com   2018-11-04           461  \n",
       "1             HackerNoon.com   2018-11-04           333  \n",
       "2             HackerNoon.com   2018-11-04           471  \n",
       "3             HackerNoon.com   2018-11-04           258  \n",
       "4             HackerNoon.com   2018-11-04           280  \n",
       "..                       ...          ...           ...  \n",
       "509  Startup Lessons Learned   2018-11-04           878  \n",
       "510                     None   2018-11-04           877  \n",
       "511                     None   2018-11-04           595  \n",
       "512              Be Yourself   2018-11-04           961  \n",
       "513              The Startup   2018-11-04           297  \n",
       "\n",
       "[514 rows x 11 columns]"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use also Length and Responses variables from test set. Responses already appear in train set as responsesCreatedCount. In addition to that we can use Length by calculating length of text values in train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set2.Responses=test_set2.Responses.str.split('\\s+').str[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We checked null values in the variables that we will use in NNs. We have to get rid of null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set2.Length.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set2.PublishedDay.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set2.Responses.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set2['Responses'] = pd.to_numeric(test_set2['Responses'], errors='coerce')\n",
    "test_set2['Responses'] = test_set2['Responses'].astype(np.float16)\n",
    "test_set2['Responses'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in test_set2.select_dtypes(include='float16').columns:\n",
    "    if test_set2[col].isna().sum() > 0:\n",
    "        m = test_set2[col].median()\n",
    "        test_set2[col].fillna(m, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got rid of null values in Responses column and changed them with mean value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 514 entries, 0 to 513\n",
      "Data columns (total 11 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Unnamed: 0    514 non-null    int64  \n",
      " 1   index         514 non-null    int64  \n",
      " 2   Author        514 non-null    object \n",
      " 3   Responses     514 non-null    float16\n",
      " 4   Header        506 non-null    object \n",
      " 5   Text          514 non-null    object \n",
      " 6   Length        514 non-null    int64  \n",
      " 7   PublishDate   514 non-null    object \n",
      " 8   WebSite       420 non-null    object \n",
      " 9   scrappedDate  514 non-null    object \n",
      " 10  PublishedDay  514 non-null    int16  \n",
      "dtypes: float16(1), int16(1), int64(3), object(6)\n",
      "memory usage: 38.3+ KB\n"
     ]
    }
   ],
   "source": [
    "test_set2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_final=test_set2[['index','Text','Length','PublishedDay','Responses']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 514 entries, 0 to 513\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   index         514 non-null    int64  \n",
      " 1   Text          514 non-null    object \n",
      " 2   Length        514 non-null    int64  \n",
      " 3   PublishedDay  514 non-null    int16  \n",
      " 4   Responses     514 non-null    float16\n",
      "dtypes: float16(1), int16(1), int64(2), object(1)\n",
      "memory usage: 14.2+ KB\n"
     ]
    }
   ],
   "source": [
    "test_set_final.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After completion of numeric variables, we can also complete all transactions on test set including tokenizetion and cleaning of text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text=test_set['Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************\n",
      "Cleaning 514 texts.\n",
      "Processed 500 reviews\n",
      "DONE\n",
      "****************************************\n"
     ]
    }
   ],
   "source": [
    "cleaned_test_text=clean_texts(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_test_text = Phrases(cleaned_test_text,min_count=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_bigram_test_text=[]\n",
    "for i in range(len(cleaned_test_text)):\n",
    "    cleaned_bigram_test_text.append(bigram_text_en[cleaned_test_text[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_final['cleaned_text_de']=cleaned_bigram_test_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_final['cleaned_text'] = [TreebankWordDetokenizer().detokenize(text) for text in cleaned_bigram_test_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 514 entries, 0 to 513\n",
      "Data columns (total 7 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   index            514 non-null    int64  \n",
      " 1   Text             514 non-null    object \n",
      " 2   Length           514 non-null    int64  \n",
      " 3   PublishedDay     514 non-null    int16  \n",
      " 4   Responses        514 non-null    float16\n",
      " 5   cleaned_text_de  514 non-null    object \n",
      " 6   cleaned_text     514 non-null    object \n",
      "dtypes: float16(1), int16(1), int64(2), object(3)\n",
      "memory usage: 22.2+ KB\n"
     ]
    }
   ],
   "source": [
    "test_set_final.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As discussed above, variables that we can use in addition to text data are responses, published day and length of the text. Now we will extract these data in train set to use them in a new NN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating PublishedDay in train set\n",
    "train_set['scrappedDate'] = pd.to_datetime(train_set['scrappedDate'], format='%Y%m%d')\n",
    "train_set['firstPublishedDate'] = pd.to_datetime(train_set['firstPublishedDate'], format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set['PublishedDay']=train_set['scrappedDate']-train_set['firstPublishedDate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set['PublishedDay'] = train_set['PublishedDay'].dt.days.astype('int16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating Length in train set\n",
    "train_set['Length']=train_set['text'].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_NN=train_set[['postId','responsesCreatedCount','PublishedDay','Length','language','totalClapCount']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_NN=train_set_NN.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_NN=train_set_NN[train_set_NN['language']=='en'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_NN=train_set_NN.drop(columns='language')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_NN['new_index']=range(len(train_set_NN))\n",
    "train_set_NN=train_set_NN.set_index(train_set_NN['new_index'],drop=True)\n",
    "train_set_NN=train_set_NN.drop(columns='new_index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have all variables below to use them to structure a neural network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>postId</th>\n",
       "      <th>responsesCreatedCount</th>\n",
       "      <th>PublishedDay</th>\n",
       "      <th>Length</th>\n",
       "      <th>totalClapCount</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new_index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10007d3018fe</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>1244</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000c43bcb97</td>\n",
       "      <td>0</td>\n",
       "      <td>301</td>\n",
       "      <td>30073</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100139913e4c</td>\n",
       "      <td>0</td>\n",
       "      <td>241</td>\n",
       "      <td>3453</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1002a55eca89</td>\n",
       "      <td>0</td>\n",
       "      <td>202</td>\n",
       "      <td>1020</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10033db0a000</td>\n",
       "      <td>0</td>\n",
       "      <td>378</td>\n",
       "      <td>10981</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66375</th>\n",
       "      <td>ffde381af7d1</td>\n",
       "      <td>1</td>\n",
       "      <td>284</td>\n",
       "      <td>6053</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66376</th>\n",
       "      <td>ffde401fb3ae</td>\n",
       "      <td>1</td>\n",
       "      <td>180</td>\n",
       "      <td>5713</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66377</th>\n",
       "      <td>ffe3f43436b8</td>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>9523</td>\n",
       "      <td>567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66378</th>\n",
       "      <td>ffefd845665f</td>\n",
       "      <td>0</td>\n",
       "      <td>342</td>\n",
       "      <td>1673</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66379</th>\n",
       "      <td>fff8e4bd6479</td>\n",
       "      <td>0</td>\n",
       "      <td>228</td>\n",
       "      <td>4787</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66380 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 postId  responsesCreatedCount  PublishedDay  Length  \\\n",
       "new_index                                                              \n",
       "0          10007d3018fe                      0            47    1244   \n",
       "1          1000c43bcb97                      0           301   30073   \n",
       "2          100139913e4c                      0           241    3453   \n",
       "3          1002a55eca89                      0           202    1020   \n",
       "4          10033db0a000                      0           378   10981   \n",
       "...                 ...                    ...           ...     ...   \n",
       "66375      ffde381af7d1                      1           284    6053   \n",
       "66376      ffde401fb3ae                      1           180    5713   \n",
       "66377      ffe3f43436b8                      0           145    9523   \n",
       "66378      ffefd845665f                      0           342    1673   \n",
       "66379      fff8e4bd6479                      0           228    4787   \n",
       "\n",
       "           totalClapCount  \n",
       "new_index                  \n",
       "0                     100  \n",
       "1                       0  \n",
       "2                       0  \n",
       "3                      50  \n",
       "4                      27  \n",
       "...                   ...  \n",
       "66375                  92  \n",
       "66376                   4  \n",
       "66377                 567  \n",
       "66378                  42  \n",
       "66379                   0  \n",
       "\n",
       "[66380 rows x 5 columns]"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set_NN.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identified x and y variables to use\n",
    "x=train_set_NN[['responsesCreatedCount','PublishedDay','Length']]\n",
    "y=train_set_NN[['totalClapCount']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imported necessary libraries for modelling\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MinMaxScaler(copy=True, feature_range=(0, 1))\n",
      "MinMaxScaler(copy=True, feature_range=(0, 1))\n"
     ]
    }
   ],
   "source": [
    "#We will scale all our numeric variables\n",
    "scaler_x = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "print(scaler_x.fit(x))\n",
    "xscale=scaler_x.transform(x)\n",
    "print(scaler_y.fit(y))\n",
    "yscale=scaler_y.transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We identified variables to train NN\n",
    "X_train=xscale\n",
    "y_train=yscale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the model that we structured before optimizing parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_var = Sequential()\n",
    "model_var.add(Dense(12, input_dim=3, kernel_initializer='normal', activation='relu'))\n",
    "model_var.add(Dense(8, activation='relu'))\n",
    "model_var.add(Dense(1, activation='linear'))\n",
    "model_var.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_var.compile(loss='mse', optimizer='adam', metrics=['mse','accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model_var.fit(X_train, y_train, epochs=50, batch_size=16,  verbose=1, validation_split=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In that part, we will optimize parameters as we learned in the tutorial. In the first phase, we optimizing batch size and epochs. We find out the best epoch and batch size parameters as 30 and 32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras import optimizers\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "def network():\n",
    "    model_var = Sequential()\n",
    "    model_var.add(Dense(12, input_dim=3, kernel_initializer='normal', activation='relu'))\n",
    "    model_var.add(Dense(8, activation='relu'))\n",
    "    model_var.add(Dense(1, activation='linear'))\n",
    "  \n",
    "    model_var.compile(loss='mse', optimizer='adam', metrics=['mse','accuracy'])\n",
    "    \n",
    "    return model_var\n",
    "\n",
    "model_var = KerasClassifier(build_fn=network, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': [32, 64, 128, 256, 512], 'epochs': [10, 30, 60]}"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batchsize = [32, 64, 128, 256, 512]\n",
    "epochs = [10,30,60]\n",
    "\n",
    "param_grid = dict(batch_size=batchsize, epochs=epochs)\n",
    "param_grid "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mahmut\\anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.007653 using {'batch_size': 32, 'epochs': 30}\n"
     ]
    }
   ],
   "source": [
    "grid = GridSearchCV(estimator=model_var, param_grid=param_grid, n_jobs=-1,cv=3)\n",
    "results = grid.fit(X_train, y_train) \n",
    "print(\"Best: %f using %s\" % (results.best_score_, results.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the second part of optimization, we looked for an ideal optimizer. You can see below that the Adamax is the ideal optimizer for our NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.002275 using {'optimizer': 'Adamax'}\n"
     ]
    }
   ],
   "source": [
    "def optim (optimizer='SGD'):\n",
    "    model_var = Sequential()\n",
    "    model_var.add(Dense(12, input_dim=3, kernel_initializer='normal', activation='relu'))\n",
    "    model_var.add(Dense(8, activation='relu'))\n",
    "    model_var.add(Dense(1, activation='linear'))\n",
    "\n",
    "    model_var.compile(loss='mse', optimizer='adam', metrics=['mse','accuracy'])\n",
    "    \n",
    "    return model_var\n",
    "\n",
    "model_var = KerasClassifier(build_fn=optim, epochs=32, batch_size=30, verbose=0)\n",
    "# define the grid search parameters\n",
    "optimizers = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
    "param_grid = dict(optimizer=optimizers) \n",
    "grid = GridSearchCV(estimator=model_var, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "results = grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best: %f using %s\" % (results.best_score_, results.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will implement results into model to idealize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_16 (Dense)             (None, 12)                48        \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 8)                 104       \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 161\n",
      "Trainable params: 161\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_var = Sequential()\n",
    "model_var.add(Dense(12, input_dim=3, kernel_initializer='normal', activation='relu'))\n",
    "model_var.add(Dense(8, activation='relu'))\n",
    "model_var.add(Dense(1, activation='linear'))\n",
    "model_var.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_var.compile(loss='mse', optimizer='Adamax', metrics=['mse','accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 49785 samples, validate on 16595 samples\n",
      "Epoch 1/30\n",
      "49785/49785 [==============================] - 2s 40us/step - loss: 4.2187e-05 - mse: 4.2187e-05 - accuracy: 0.3675 - val_loss: 3.7783e-05 - val_mse: 3.7783e-05 - val_accuracy: 0.1544\n",
      "Epoch 2/30\n",
      "49785/49785 [==============================] - 2s 35us/step - loss: 4.1542e-05 - mse: 4.1542e-05 - accuracy: 0.3675 - val_loss: 3.7002e-05 - val_mse: 3.7002e-05 - val_accuracy: 0.1544\n",
      "Epoch 3/30\n",
      "49785/49785 [==============================] - 2s 35us/step - loss: 4.1091e-05 - mse: 4.1091e-05 - accuracy: 0.3675 - val_loss: 3.6316e-05 - val_mse: 3.6316e-05 - val_accuracy: 0.1544\n",
      "Epoch 4/30\n",
      "49785/49785 [==============================] - 2s 40us/step - loss: 4.0504e-05 - mse: 4.0504e-05 - accuracy: 0.3675 - val_loss: 3.5736e-05 - val_mse: 3.5736e-05 - val_accuracy: 0.1544\n",
      "Epoch 5/30\n",
      "49785/49785 [==============================] - 2s 43us/step - loss: 3.9952e-05 - mse: 3.9952e-05 - accuracy: 0.3675 - val_loss: 3.4465e-05 - val_mse: 3.4465e-05 - val_accuracy: 0.1544\n",
      "Epoch 6/30\n",
      "49785/49785 [==============================] - 2s 42us/step - loss: 3.9141e-05 - mse: 3.9141e-05 - accuracy: 0.3675 - val_loss: 3.3837e-05 - val_mse: 3.3837e-05 - val_accuracy: 0.1544\n",
      "Epoch 7/30\n",
      "49785/49785 [==============================] - 2s 37us/step - loss: 3.8236e-05 - mse: 3.8236e-05 - accuracy: 0.3675 - val_loss: 3.2360e-05 - val_mse: 3.2360e-05 - val_accuracy: 0.1544\n",
      "Epoch 8/30\n",
      "49785/49785 [==============================] - 2s 38us/step - loss: 3.7383e-05 - mse: 3.7382e-05 - accuracy: 0.3675 - val_loss: 3.0726e-05 - val_mse: 3.0726e-05 - val_accuracy: 0.1544\n",
      "Epoch 9/30\n",
      "49785/49785 [==============================] - 2s 36us/step - loss: 3.6352e-05 - mse: 3.6352e-05 - accuracy: 0.3675 - val_loss: 2.8583e-05 - val_mse: 2.8583e-05 - val_accuracy: 0.1544\n",
      "Epoch 10/30\n",
      "49785/49785 [==============================] - 2s 37us/step - loss: 3.5188e-05 - mse: 3.5188e-05 - accuracy: 0.3675 - val_loss: 2.6726e-05 - val_mse: 2.6726e-05 - val_accuracy: 0.1544\n",
      "Epoch 11/30\n",
      "49785/49785 [==============================] - 2s 36us/step - loss: 3.4186e-05 - mse: 3.4186e-05 - accuracy: 0.3675 - val_loss: 2.7323e-05 - val_mse: 2.7323e-05 - val_accuracy: 0.1544\n",
      "Epoch 12/30\n",
      "49785/49785 [==============================] - 2s 36us/step - loss: 3.3378e-05 - mse: 3.3378e-05 - accuracy: 0.3675 - val_loss: 2.4339e-05 - val_mse: 2.4339e-05 - val_accuracy: 0.1544\n",
      "Epoch 13/30\n",
      "49785/49785 [==============================] - 2s 36us/step - loss: 3.2276e-05 - mse: 3.2276e-05 - accuracy: 0.3675 - val_loss: 2.2609e-05 - val_mse: 2.2609e-05 - val_accuracy: 0.1544\n",
      "Epoch 14/30\n",
      "49785/49785 [==============================] - 2s 43us/step - loss: 3.0988e-05 - mse: 3.0988e-05 - accuracy: 0.3675 - val_loss: 2.0990e-05 - val_mse: 2.0990e-05 - val_accuracy: 0.1544\n",
      "Epoch 15/30\n",
      "49785/49785 [==============================] - 2s 38us/step - loss: 2.9832e-05 - mse: 2.9832e-05 - accuracy: 0.3675 - val_loss: 1.9382e-05 - val_mse: 1.9382e-05 - val_accuracy: 0.1544\n",
      "Epoch 16/30\n",
      "49785/49785 [==============================] - 2s 36us/step - loss: 2.9008e-05 - mse: 2.9008e-05 - accuracy: 0.3675 - val_loss: 1.8180e-05 - val_mse: 1.8180e-05 - val_accuracy: 0.1544\n",
      "Epoch 17/30\n",
      "49785/49785 [==============================] - 2s 36us/step - loss: 2.8034e-05 - mse: 2.8034e-05 - accuracy: 0.3675 - val_loss: 1.7082e-05 - val_mse: 1.7082e-05 - val_accuracy: 0.1544\n",
      "Epoch 18/30\n",
      "49785/49785 [==============================] - 2s 36us/step - loss: 2.7220e-05 - mse: 2.7220e-05 - accuracy: 0.3675 - val_loss: 1.6102e-05 - val_mse: 1.6102e-05 - val_accuracy: 0.1544\n",
      "Epoch 19/30\n",
      "49785/49785 [==============================] - 2s 36us/step - loss: 2.6669e-05 - mse: 2.6669e-05 - accuracy: 0.3675 - val_loss: 1.7821e-05 - val_mse: 1.7821e-05 - val_accuracy: 0.1544\n",
      "Epoch 20/30\n",
      "49785/49785 [==============================] - 2s 36us/step - loss: 2.6019e-05 - mse: 2.6019e-05 - accuracy: 0.3675 - val_loss: 1.5843e-05 - val_mse: 1.5843e-05 - val_accuracy: 0.1544\n",
      "Epoch 21/30\n",
      "49785/49785 [==============================] - 2s 36us/step - loss: 2.5309e-05 - mse: 2.5309e-05 - accuracy: 0.3675 - val_loss: 1.5578e-05 - val_mse: 1.5578e-05 - val_accuracy: 0.1544\n",
      "Epoch 22/30\n",
      "49785/49785 [==============================] - 2s 36us/step - loss: 2.4752e-05 - mse: 2.4752e-05 - accuracy: 0.3675 - val_loss: 1.4384e-05 - val_mse: 1.4384e-05 - val_accuracy: 0.1544\n",
      "Epoch 23/30\n",
      "49785/49785 [==============================] - 2s 43us/step - loss: 2.4525e-05 - mse: 2.4525e-05 - accuracy: 0.3675 - val_loss: 1.4300e-05 - val_mse: 1.4300e-05 - val_accuracy: 0.1544\n",
      "Epoch 24/30\n",
      "49785/49785 [==============================] - 2s 38us/step - loss: 2.4185e-05 - mse: 2.4185e-05 - accuracy: 0.3675 - val_loss: 1.3070e-05 - val_mse: 1.3070e-05 - val_accuracy: 0.1544\n",
      "Epoch 25/30\n",
      "49785/49785 [==============================] - 2s 36us/step - loss: 2.3842e-05 - mse: 2.3842e-05 - accuracy: 0.3675 - val_loss: 1.3044e-05 - val_mse: 1.3044e-05 - val_accuracy: 0.1544\n",
      "Epoch 26/30\n",
      "49785/49785 [==============================] - 2s 36us/step - loss: 2.3747e-05 - mse: 2.3747e-05 - accuracy: 0.3675 - val_loss: 1.2683e-05 - val_mse: 1.2683e-05 - val_accuracy: 0.1544\n",
      "Epoch 27/30\n",
      "49785/49785 [==============================] - 2s 36us/step - loss: 2.3428e-05 - mse: 2.3428e-05 - accuracy: 0.3675 - val_loss: 1.2322e-05 - val_mse: 1.2322e-05 - val_accuracy: 0.1544\n",
      "Epoch 28/30\n",
      "49785/49785 [==============================] - 2s 36us/step - loss: 2.3073e-05 - mse: 2.3073e-05 - accuracy: 0.3675 - val_loss: 1.2356e-05 - val_mse: 1.2356e-05 - val_accuracy: 0.1544\n",
      "Epoch 29/30\n",
      "49785/49785 [==============================] - 2s 36us/step - loss: 2.2893e-05 - mse: 2.2893e-05 - accuracy: 0.3675 - val_loss: 1.1942e-05 - val_mse: 1.1942e-05 - val_accuracy: 0.1544\n",
      "Epoch 30/30\n",
      "49785/49785 [==============================] - 2s 36us/step - loss: 2.2828e-05 - mse: 2.2828e-05 - accuracy: 0.3675 - val_loss: 1.1940e-05 - val_mse: 1.1940e-05 - val_accuracy: 0.1544\n"
     ]
    }
   ],
   "source": [
    "history = model_var.fit(X_train, y_train, epochs=30, batch_size=32,  verbose=1, validation_split=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_mse', 'val_accuracy', 'loss', 'mse', 'accuracy'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(history.history.keys())\n",
    "# \"Loss\"\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Step: Structuring Final Model\n",
    "In this step, we will put all train set variables into ideal NLP and NN models that we pick above and we will predict some clap counts. As a last step, we will combine these variables and will make our last value predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using all train set rows to extract our Variable based Neural Network Predictions\n",
    "y_val_NN=model_var.predict(xscale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.1308491e-04],\n",
       "       [ 7.1950257e-04],\n",
       "       [ 7.2628260e-05],\n",
       "       ...,\n",
       "       [ 1.4351308e-04],\n",
       "       [ 1.0275841e-04],\n",
       "       [ 9.3862414e-05]], dtype=float32)"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val_NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making inverse transformation to get exact values\n",
    "Y_hat_NN=scaler_y.inverse_transform(y_val_NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-32.98755 ],\n",
       "       [209.88321 ],\n",
       "       [ 21.1861  ],\n",
       "       ...,\n",
       "       [ 41.86363 ],\n",
       "       [ 29.975245],\n",
       "       [ 27.38023 ]], dtype=float32)"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_hat_NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding predictions to data frame\n",
    "train_set_NN['y_hat_NN']=pd.DataFrame(Y_hat_NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using all training set rows to extract our ideal NLP model prediction results\n",
    "y_val_NLP=model2.predict(X_tr_int_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding predictions to data frame\n",
    "train_set_NN['y_val_NLP']=pd.DataFrame(y_val_NLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making inverse log transformation\n",
    "train_set_NN['y_hat_NLP']=(np.exp(train_set_NN['y_val_NLP']))-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_NN=train_set_NN.drop(columns='y_val_NLP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>postId</th>\n",
       "      <th>responsesCreatedCount</th>\n",
       "      <th>PublishedDay</th>\n",
       "      <th>Length</th>\n",
       "      <th>totalClapCount</th>\n",
       "      <th>y_hat_NLP</th>\n",
       "      <th>y_hat_NN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new_index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10007d3018fe</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>1244</td>\n",
       "      <td>100</td>\n",
       "      <td>1.716988</td>\n",
       "      <td>-32.987549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000c43bcb97</td>\n",
       "      <td>0</td>\n",
       "      <td>301</td>\n",
       "      <td>30073</td>\n",
       "      <td>0</td>\n",
       "      <td>1.718036</td>\n",
       "      <td>209.883209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100139913e4c</td>\n",
       "      <td>0</td>\n",
       "      <td>241</td>\n",
       "      <td>3453</td>\n",
       "      <td>0</td>\n",
       "      <td>1.709819</td>\n",
       "      <td>21.186100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1002a55eca89</td>\n",
       "      <td>0</td>\n",
       "      <td>202</td>\n",
       "      <td>1020</td>\n",
       "      <td>50</td>\n",
       "      <td>1.716948</td>\n",
       "      <td>-2.888421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10033db0a000</td>\n",
       "      <td>0</td>\n",
       "      <td>378</td>\n",
       "      <td>10981</td>\n",
       "      <td>27</td>\n",
       "      <td>1.717958</td>\n",
       "      <td>99.010460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66375</th>\n",
       "      <td>ffde381af7d1</td>\n",
       "      <td>1</td>\n",
       "      <td>284</td>\n",
       "      <td>6053</td>\n",
       "      <td>92</td>\n",
       "      <td>1.718151</td>\n",
       "      <td>195.117279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66376</th>\n",
       "      <td>ffde401fb3ae</td>\n",
       "      <td>1</td>\n",
       "      <td>180</td>\n",
       "      <td>5713</td>\n",
       "      <td>4</td>\n",
       "      <td>1.718076</td>\n",
       "      <td>171.677383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66377</th>\n",
       "      <td>ffe3f43436b8</td>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>9523</td>\n",
       "      <td>567</td>\n",
       "      <td>1.717938</td>\n",
       "      <td>41.863628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66378</th>\n",
       "      <td>ffefd845665f</td>\n",
       "      <td>0</td>\n",
       "      <td>342</td>\n",
       "      <td>1673</td>\n",
       "      <td>42</td>\n",
       "      <td>1.718146</td>\n",
       "      <td>29.975245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66379</th>\n",
       "      <td>fff8e4bd6479</td>\n",
       "      <td>0</td>\n",
       "      <td>228</td>\n",
       "      <td>4787</td>\n",
       "      <td>0</td>\n",
       "      <td>1.718128</td>\n",
       "      <td>27.380230</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66380 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 postId  responsesCreatedCount  PublishedDay  Length  \\\n",
       "new_index                                                              \n",
       "0          10007d3018fe                      0            47    1244   \n",
       "1          1000c43bcb97                      0           301   30073   \n",
       "2          100139913e4c                      0           241    3453   \n",
       "3          1002a55eca89                      0           202    1020   \n",
       "4          10033db0a000                      0           378   10981   \n",
       "...                 ...                    ...           ...     ...   \n",
       "66375      ffde381af7d1                      1           284    6053   \n",
       "66376      ffde401fb3ae                      1           180    5713   \n",
       "66377      ffe3f43436b8                      0           145    9523   \n",
       "66378      ffefd845665f                      0           342    1673   \n",
       "66379      fff8e4bd6479                      0           228    4787   \n",
       "\n",
       "           totalClapCount  y_hat_NLP    y_hat_NN  \n",
       "new_index                                         \n",
       "0                     100   1.716988  -32.987549  \n",
       "1                       0   1.718036  209.883209  \n",
       "2                       0   1.709819   21.186100  \n",
       "3                      50   1.716948   -2.888421  \n",
       "4                      27   1.717958   99.010460  \n",
       "...                   ...        ...         ...  \n",
       "66375                  92   1.718151  195.117279  \n",
       "66376                   4   1.718076  171.677383  \n",
       "66377                 567   1.717938   41.863628  \n",
       "66378                  42   1.718146   29.975245  \n",
       "66379                   0   1.718128   27.380230  \n",
       "\n",
       "[66380 rows x 7 columns]"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set_NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the final model. We will put our prediction results from both model into a new neural network to predict final clap predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_x=train_set_NN[['y_hat_NLP','y_hat_NN']]\n",
    "final_y=train_set_NN[['totalClapCount']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_50 (Dense)             (None, 12)                36        \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 8)                 104       \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 149\n",
      "Trainable params: 149\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_last = Sequential()\n",
    "model_last.add(Dense(12, input_dim=2, kernel_initializer='normal', activation='relu'))\n",
    "model_last.add(Dense(8, activation='relu'))\n",
    "model_last.add(Dense(1, activation='linear'))\n",
    "model_last.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_last.compile(loss='mse', optimizer='Adamax', metrics=['mse','accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 49785 samples, validate on 16595 samples\n",
      "Epoch 1/30\n",
      "49785/49785 [==============================] - 0s 5us/step - loss: 1799151.8954 - mse: 1799151.8750 - accuracy: 0.0023 - val_loss: 960041.7904 - val_mse: 960041.8125 - val_accuracy: 0.0027\n",
      "Epoch 2/30\n",
      "49785/49785 [==============================] - 0s 5us/step - loss: 1787063.1548 - mse: 1787063.2500 - accuracy: 0.0023 - val_loss: 960027.9533 - val_mse: 960027.9375 - val_accuracy: 0.0031\n",
      "Epoch 3/30\n",
      "49785/49785 [==============================] - 0s 5us/step - loss: 1785495.9306 - mse: 1785496.1250 - accuracy: 0.0021 - val_loss: 960259.9534 - val_mse: 960260.0625 - val_accuracy: 0.0027\n",
      "Epoch 4/30\n",
      "49785/49785 [==============================] - 0s 7us/step - loss: 1785461.8252 - mse: 1785461.7500 - accuracy: 0.0022 - val_loss: 960411.4213 - val_mse: 960411.4375 - val_accuracy: 0.0025\n",
      "Epoch 5/30\n",
      "49785/49785 [==============================] - 0s 5us/step - loss: 1784409.3440 - mse: 1784409.2500 - accuracy: 0.0023 - val_loss: 961212.0228 - val_mse: 961212.0000 - val_accuracy: 0.0025\n",
      "Epoch 6/30\n",
      "49785/49785 [==============================] - 0s 6us/step - loss: 1782685.1900 - mse: 1782685.3750 - accuracy: 0.0022 - val_loss: 962669.7578 - val_mse: 962669.6250 - val_accuracy: 0.0022\n",
      "Epoch 7/30\n",
      "49785/49785 [==============================] - 0s 4us/step - loss: 1774322.3198 - mse: 1774322.5000 - accuracy: 0.0024 - val_loss: 963106.4614 - val_mse: 963106.5000 - val_accuracy: 0.0026\n",
      "Epoch 8/30\n",
      "49785/49785 [==============================] - 0s 6us/step - loss: 1776293.1576 - mse: 1776293.0000 - accuracy: 0.0023 - val_loss: 964372.0538 - val_mse: 964372.0625 - val_accuracy: 0.0030\n",
      "Epoch 9/30\n",
      "49785/49785 [==============================] - 0s 7us/step - loss: 1779084.5553 - mse: 1779084.3750 - accuracy: 0.0026 - val_loss: 965850.5522 - val_mse: 965850.4375 - val_accuracy: 0.0028\n",
      "Epoch 10/30\n",
      "49785/49785 [==============================] - 0s 8us/step - loss: 1775472.7004 - mse: 1775472.2500 - accuracy: 0.0031 - val_loss: 966964.6978 - val_mse: 966964.5625 - val_accuracy: 0.0030\n",
      "Epoch 11/30\n",
      "49785/49785 [==============================] - 0s 8us/step - loss: 1780971.4605 - mse: 1780971.3750 - accuracy: 0.0034 - val_loss: 966412.8663 - val_mse: 966412.8125 - val_accuracy: 0.0037\n",
      "Epoch 12/30\n",
      "49785/49785 [==============================] - 0s 8us/step - loss: 1773225.7455 - mse: 1773225.8750 - accuracy: 0.0035 - val_loss: 966849.7314 - val_mse: 966849.6875 - val_accuracy: 0.0035\n",
      "Epoch 13/30\n",
      "49785/49785 [==============================] - 0s 5us/step - loss: 1775128.5273 - mse: 1775128.1250 - accuracy: 0.0030 - val_loss: 970287.1093 - val_mse: 970287.0625 - val_accuracy: 0.0033\n",
      "Epoch 14/30\n",
      "49785/49785 [==============================] - 0s 5us/step - loss: 1770180.5233 - mse: 1770180.8750 - accuracy: 0.0026 - val_loss: 971789.6752 - val_mse: 971789.6875 - val_accuracy: 0.0030\n",
      "Epoch 15/30\n",
      "49785/49785 [==============================] - 0s 7us/step - loss: 1771239.7969 - mse: 1771239.7500 - accuracy: 0.0030 - val_loss: 974199.5699 - val_mse: 974199.5625 - val_accuracy: 0.0028\n",
      "Epoch 16/30\n",
      "49785/49785 [==============================] - 0s 8us/step - loss: 1769812.5689 - mse: 1769812.0000 - accuracy: 0.0029 - val_loss: 974753.0156 - val_mse: 974753.0625 - val_accuracy: 0.0031\n",
      "Epoch 17/30\n",
      "49785/49785 [==============================] - 0s 5us/step - loss: 1773334.8927 - mse: 1773334.7500 - accuracy: 0.0029 - val_loss: 972338.4236 - val_mse: 972338.3125 - val_accuracy: 0.0031\n",
      "Epoch 18/30\n",
      "49785/49785 [==============================] - 0s 5us/step - loss: 1774341.7713 - mse: 1774341.2500 - accuracy: 0.0030 - val_loss: 974217.8599 - val_mse: 974217.8125 - val_accuracy: 0.0031\n",
      "Epoch 19/30\n",
      "49785/49785 [==============================] - 0s 7us/step - loss: 1765365.9363 - mse: 1765365.5000 - accuracy: 0.0029 - val_loss: 977496.3356 - val_mse: 977496.4375 - val_accuracy: 0.0034\n",
      "Epoch 20/30\n",
      "49785/49785 [==============================] - 0s 7us/step - loss: 1772100.4286 - mse: 1772100.3750 - accuracy: 0.0027 - val_loss: 981085.3386 - val_mse: 981085.3750 - val_accuracy: 0.0031\n",
      "Epoch 21/30\n",
      "49785/49785 [==============================] - 0s 6us/step - loss: 1766310.1544 - mse: 1766310.0000 - accuracy: 0.0029 - val_loss: 978705.6818 - val_mse: 978705.8125 - val_accuracy: 0.0027\n",
      "Epoch 22/30\n",
      "49785/49785 [==============================] - 0s 5us/step - loss: 1769703.1651 - mse: 1769702.8750 - accuracy: 0.0029 - val_loss: 979564.0971 - val_mse: 979564.0000 - val_accuracy: 0.0023\n",
      "Epoch 23/30\n",
      "49785/49785 [==============================] - 0s 5us/step - loss: 1767839.8654 - mse: 1767839.8750 - accuracy: 0.0030 - val_loss: 978201.2848 - val_mse: 978201.1875 - val_accuracy: 0.0022\n",
      "Epoch 24/30\n",
      "49785/49785 [==============================] - 0s 5us/step - loss: 1775522.2541 - mse: 1775522.2500 - accuracy: 0.0030 - val_loss: 976372.5228 - val_mse: 976372.4375 - val_accuracy: 0.0020\n",
      "Epoch 25/30\n",
      "49785/49785 [==============================] - 0s 5us/step - loss: 1768777.8001 - mse: 1768778.0000 - accuracy: 0.0028 - val_loss: 980689.2086 - val_mse: 980689.2500 - val_accuracy: 0.0024\n",
      "Epoch 26/30\n",
      "49785/49785 [==============================] - 0s 6us/step - loss: 1767764.4176 - mse: 1767764.0000 - accuracy: 0.0026 - val_loss: 981690.6401 - val_mse: 981690.6875 - val_accuracy: 0.0022\n",
      "Epoch 27/30\n",
      "49785/49785 [==============================] - 0s 7us/step - loss: 1769629.6750 - mse: 1769629.6250 - accuracy: 0.0027 - val_loss: 981989.0361 - val_mse: 981989.1250 - val_accuracy: 0.0023\n",
      "Epoch 28/30\n",
      "49785/49785 [==============================] - 0s 7us/step - loss: 1767603.4483 - mse: 1767603.3750 - accuracy: 0.0030 - val_loss: 982410.3037 - val_mse: 982410.3125 - val_accuracy: 0.0024\n",
      "Epoch 29/30\n",
      "49785/49785 [==============================] - 0s 6us/step - loss: 1776225.1392 - mse: 1776224.8750 - accuracy: 0.0026 - val_loss: 982184.1147 - val_mse: 982184.0625 - val_accuracy: 0.0021\n",
      "Epoch 30/30\n",
      "49785/49785 [==============================] - 0s 5us/step - loss: 1766574.9516 - mse: 1766574.7500 - accuracy: 0.0025 - val_loss: 985018.7544 - val_mse: 985018.8750 - val_accuracy: 0.0022\n"
     ]
    }
   ],
   "source": [
    "history = model_last.fit(final_x, final_y, epochs=30, batch_size=502,  verbose=1, validation_split=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now it is time to implement on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implemented NLP model to our text in test set \n",
    "x_nlp=test_set_final['cleaned_text']\n",
    "tok_obj_x_nlp = Tokenizer(NUM_WORDS, oov_token=1)  \n",
    "tokenizer_obj.fit_on_texts(x_nlp) \n",
    "x_nlp_int = tokenizer_obj.texts_to_sequences(x_nlp)\n",
    "x_nlp_int_pad = pad_sequences(x_nlp_int, MAX_REVIEW_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "514/514 [==============================] - 2s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "test_nlp_predict=model2.predict(x_nlp_int_pad,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implemented NN model to our other variables in test set\n",
    "x_nn=test_set_final[['Length','Responses','PublishedDay']].copy()\n",
    "test_nn_raw_predict=model_var.predict(x_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Integrating results into final dataframe\n",
    "test_set_final['nlp_predict']=test_nlp_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Integrating results into final dataframe\n",
    "test_set_final['nn_raw_predict']=test_nn_raw_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inverse log transformation for nlp predictions\n",
    "test_set_final['nlp_raw_predict']=(np.exp(test_set_final['nlp_predict']))-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Text</th>\n",
       "      <th>Length</th>\n",
       "      <th>PublishedDay</th>\n",
       "      <th>Responses</th>\n",
       "      <th>cleaned_text_de</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>nlp_predict</th>\n",
       "      <th>nn_raw_predict</th>\n",
       "      <th>nlp_raw_predict</th>\n",
       "      <th>fin_pred</th>\n",
       "      <th>Claps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>There’s one incredible feature of cryptocurren...</td>\n",
       "      <td>23401</td>\n",
       "      <td>461</td>\n",
       "      <td>627.0</td>\n",
       "      <td>[one, incredible, feature, cryptocurrencies, a...</td>\n",
       "      <td>one incredible feature cryptocurrencies almost...</td>\n",
       "      <td>0.994026</td>\n",
       "      <td>2790.042725</td>\n",
       "      <td>1.702092</td>\n",
       "      <td>37030.414062</td>\n",
       "      <td>37030.414062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>&lt;img class=\"progressiveMedia-noscript js-progr...</td>\n",
       "      <td>23972</td>\n",
       "      <td>333</td>\n",
       "      <td>156.0</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>0.035058</td>\n",
       "      <td>2828.730225</td>\n",
       "      <td>0.035680</td>\n",
       "      <td>37543.906250</td>\n",
       "      <td>37543.906250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>So you want to trade cryptocurrency?You’ve see...</td>\n",
       "      <td>402</td>\n",
       "      <td>471</td>\n",
       "      <td>176.0</td>\n",
       "      <td>[want, trade, cryptocurrency, see, eye, pop, r...</td>\n",
       "      <td>want trade cryptocurrency see eye pop return w...</td>\n",
       "      <td>0.999197</td>\n",
       "      <td>78.934425</td>\n",
       "      <td>1.716100</td>\n",
       "      <td>1062.038574</td>\n",
       "      <td>1062.038574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>A useful currency should be a medium of exchan...</td>\n",
       "      <td>19730</td>\n",
       "      <td>258</td>\n",
       "      <td>72.0</td>\n",
       "      <td>[useful, currency, medium, exchange, unit, acc...</td>\n",
       "      <td>useful currency medium exchange unit account s...</td>\n",
       "      <td>0.999855</td>\n",
       "      <td>2324.803223</td>\n",
       "      <td>1.717889</td>\n",
       "      <td>30858.166016</td>\n",
       "      <td>30858.166016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>Crypto crypto crypto crypto. It’s here. It’s h...</td>\n",
       "      <td>5324</td>\n",
       "      <td>280</td>\n",
       "      <td>19.0</td>\n",
       "      <td>[crypto, crypto, crypto, crypto, happen, big, ...</td>\n",
       "      <td>crypto crypto crypto crypto happen big way fas...</td>\n",
       "      <td>0.999079</td>\n",
       "      <td>642.586121</td>\n",
       "      <td>1.715780</td>\n",
       "      <td>8540.032227</td>\n",
       "      <td>8540.032227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>598</td>\n",
       "      <td>I just did what no startup founder is ever sup...</td>\n",
       "      <td>9025</td>\n",
       "      <td>878</td>\n",
       "      <td>181.0</td>\n",
       "      <td>[startup, founder, ever, suppose, give, even, ...</td>\n",
       "      <td>startup founder ever suppose give even one glo...</td>\n",
       "      <td>0.996289</td>\n",
       "      <td>1124.045532</td>\n",
       "      <td>1.708213</td>\n",
       "      <td>14927.567383</td>\n",
       "      <td>14927.567383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>599</td>\n",
       "      <td>If you’re embarking on the startup journey and...</td>\n",
       "      <td>5571</td>\n",
       "      <td>877</td>\n",
       "      <td>24.0</td>\n",
       "      <td>[embark, startup, journey, know, tackle, first...</td>\n",
       "      <td>embark startup journey know tackle first long ...</td>\n",
       "      <td>0.999912</td>\n",
       "      <td>714.513550</td>\n",
       "      <td>1.718043</td>\n",
       "      <td>9494.291992</td>\n",
       "      <td>9494.291992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>600</td>\n",
       "      <td>Fuck you startups with your extravagant partie...</td>\n",
       "      <td>475</td>\n",
       "      <td>595</td>\n",
       "      <td>24.0</td>\n",
       "      <td>[fuck, startup, extravagant, party, crazy, sit...</td>\n",
       "      <td>fuck startup extravagant party crazy site even...</td>\n",
       "      <td>0.997647</td>\n",
       "      <td>91.513954</td>\n",
       "      <td>1.711893</td>\n",
       "      <td>1228.931763</td>\n",
       "      <td>1228.931763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>601</td>\n",
       "      <td>Note: This is not a post to glorify prostituti...</td>\n",
       "      <td>13483</td>\n",
       "      <td>961</td>\n",
       "      <td>116.0</td>\n",
       "      <td>[note, post, glorify, prostitution, criticise,...</td>\n",
       "      <td>note post glorify prostitution criticise start...</td>\n",
       "      <td>0.999798</td>\n",
       "      <td>1647.823608</td>\n",
       "      <td>1.717733</td>\n",
       "      <td>21876.552734</td>\n",
       "      <td>21876.552734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>602</td>\n",
       "      <td>Question: What do Craigslist and Albert Einste...</td>\n",
       "      <td>8736</td>\n",
       "      <td>297</td>\n",
       "      <td>34.0</td>\n",
       "      <td>[question, craigslist, albert_einstein, common...</td>\n",
       "      <td>question craigslist albert_einstein common ans...</td>\n",
       "      <td>0.999932</td>\n",
       "      <td>1042.705322</td>\n",
       "      <td>1.718096</td>\n",
       "      <td>13848.422852</td>\n",
       "      <td>13848.422852</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>514 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index                                               Text  Length  \\\n",
       "0        0  There’s one incredible feature of cryptocurren...   23401   \n",
       "1        1  <img class=\"progressiveMedia-noscript js-progr...   23972   \n",
       "2        2  So you want to trade cryptocurrency?You’ve see...     402   \n",
       "3        5  A useful currency should be a medium of exchan...   19730   \n",
       "4        7  Crypto crypto crypto crypto. It’s here. It’s h...    5324   \n",
       "..     ...                                                ...     ...   \n",
       "509    598  I just did what no startup founder is ever sup...    9025   \n",
       "510    599  If you’re embarking on the startup journey and...    5571   \n",
       "511    600  Fuck you startups with your extravagant partie...     475   \n",
       "512    601  Note: This is not a post to glorify prostituti...   13483   \n",
       "513    602  Question: What do Craigslist and Albert Einste...    8736   \n",
       "\n",
       "     PublishedDay  Responses  \\\n",
       "0             461      627.0   \n",
       "1             333      156.0   \n",
       "2             471      176.0   \n",
       "3             258       72.0   \n",
       "4             280       19.0   \n",
       "..            ...        ...   \n",
       "509           878      181.0   \n",
       "510           877       24.0   \n",
       "511           595       24.0   \n",
       "512           961      116.0   \n",
       "513           297       34.0   \n",
       "\n",
       "                                       cleaned_text_de  \\\n",
       "0    [one, incredible, feature, cryptocurrencies, a...   \n",
       "1                                                   []   \n",
       "2    [want, trade, cryptocurrency, see, eye, pop, r...   \n",
       "3    [useful, currency, medium, exchange, unit, acc...   \n",
       "4    [crypto, crypto, crypto, crypto, happen, big, ...   \n",
       "..                                                 ...   \n",
       "509  [startup, founder, ever, suppose, give, even, ...   \n",
       "510  [embark, startup, journey, know, tackle, first...   \n",
       "511  [fuck, startup, extravagant, party, crazy, sit...   \n",
       "512  [note, post, glorify, prostitution, criticise,...   \n",
       "513  [question, craigslist, albert_einstein, common...   \n",
       "\n",
       "                                          cleaned_text  nlp_predict  \\\n",
       "0    one incredible feature cryptocurrencies almost...     0.994026   \n",
       "1                                                          0.035058   \n",
       "2    want trade cryptocurrency see eye pop return w...     0.999197   \n",
       "3    useful currency medium exchange unit account s...     0.999855   \n",
       "4    crypto crypto crypto crypto happen big way fas...     0.999079   \n",
       "..                                                 ...          ...   \n",
       "509  startup founder ever suppose give even one glo...     0.996289   \n",
       "510  embark startup journey know tackle first long ...     0.999912   \n",
       "511  fuck startup extravagant party crazy site even...     0.997647   \n",
       "512  note post glorify prostitution criticise start...     0.999798   \n",
       "513  question craigslist albert_einstein common ans...     0.999932   \n",
       "\n",
       "     nn_raw_predict  nlp_raw_predict      fin_pred         Claps  \n",
       "0       2790.042725         1.702092  37030.414062  37030.414062  \n",
       "1       2828.730225         0.035680  37543.906250  37543.906250  \n",
       "2         78.934425         1.716100   1062.038574   1062.038574  \n",
       "3       2324.803223         1.717889  30858.166016  30858.166016  \n",
       "4        642.586121         1.715780   8540.032227   8540.032227  \n",
       "..              ...              ...           ...           ...  \n",
       "509     1124.045532         1.708213  14927.567383  14927.567383  \n",
       "510      714.513550         1.718043   9494.291992   9494.291992  \n",
       "511       91.513954         1.711893   1228.931763   1228.931763  \n",
       "512     1647.823608         1.717733  21876.552734  21876.552734  \n",
       "513     1042.705322         1.718096  13848.422852  13848.422852  \n",
       "\n",
       "[514 rows x 12 columns]"
      ]
     },
     "execution_count": 478,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we get first phase result and identify them as final variables to use as input in final NLP\n",
    "fin_var=test_set_final[['nn_raw_predict','nlp_raw_predict']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_pred=model_last.predict(fin_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[37904.516  ],\n",
       "       [38430.3    ],\n",
       "       [ 1082.6211 ],\n",
       "       [31585.701  ],\n",
       "       [ 8738.06   ],\n",
       "       [51671.71   ],\n",
       "       [ 5805.5376 ],\n",
       "       [ 8509.992  ],\n",
       "       [47785.17   ],\n",
       "       [  906.77954],\n",
       "       [ 2906.4534 ],\n",
       "       [ 2549.9478 ],\n",
       "       [ 2762.1504 ],\n",
       "       [32305.068  ],\n",
       "       [22576.9    ],\n",
       "       [10951.962  ],\n",
       "       [11569.624  ],\n",
       "       [19300.854  ],\n",
       "       [ 2025.8151 ],\n",
       "       [15533.556  ],\n",
       "       [10771.849  ],\n",
       "       [ 4676.5083 ],\n",
       "       [44673.49   ],\n",
       "       [27661.418  ],\n",
       "       [ 5550.272  ],\n",
       "       [27918.049  ],\n",
       "       [ 9561.474  ],\n",
       "       [15160.096  ],\n",
       "       [ 1922.933  ],\n",
       "       [ 3631.415  ],\n",
       "       [  927.83374],\n",
       "       [ 4945.5796 ],\n",
       "       [23708.252  ],\n",
       "       [14500.993  ],\n",
       "       [13424.188  ],\n",
       "       [19483.678  ],\n",
       "       [21408.033  ],\n",
       "       [  968.11346],\n",
       "       [12365.898  ],\n",
       "       [  531.467  ],\n",
       "       [ 9922.823  ],\n",
       "       [ 1953.2941 ],\n",
       "       [18411.037  ],\n",
       "       [ 6788.019  ],\n",
       "       [ 1115.3761 ],\n",
       "       [16273.297  ],\n",
       "       [ 1408.7603 ],\n",
       "       [  981.38654],\n",
       "       [ 1416.6276 ],\n",
       "       [ 9351.626  ],\n",
       "       [ 4051.9844 ],\n",
       "       [ 1057.0593 ],\n",
       "       [  762.3447 ],\n",
       "       [18810.531  ],\n",
       "       [21395.709  ],\n",
       "       [  872.16345],\n",
       "       [16310.528  ],\n",
       "       [ 3140.8223 ],\n",
       "       [  427.44788],\n",
       "       [16217.241  ],\n",
       "       [ 9668.318  ],\n",
       "       [ 6800.2256 ],\n",
       "       [ 6920.938  ],\n",
       "       [52143.38   ],\n",
       "       [ 6624.466  ],\n",
       "       [  829.32916],\n",
       "       [ 2719.9167 ],\n",
       "       [ 9834.198  ],\n",
       "       [ 2814.025  ],\n",
       "       [ 7594.6597 ],\n",
       "       [ 7987.3677 ],\n",
       "       [  743.0989 ],\n",
       "       [  917.0072 ],\n",
       "       [ 2028.2837 ],\n",
       "       [  853.0314 ],\n",
       "       [10378.921  ],\n",
       "       [  460.22336],\n",
       "       [ 5576.9536 ],\n",
       "       [ 1599.45   ],\n",
       "       [  922.2694 ],\n",
       "       [  499.29016],\n",
       "       [ 7993.601  ],\n",
       "       [ 2477.934  ],\n",
       "       [  716.70715],\n",
       "       [ 1007.52136],\n",
       "       [10481.1    ],\n",
       "       [ 1845.4985 ],\n",
       "       [  935.6428 ],\n",
       "       [ 3501.6501 ],\n",
       "       [ 6850.561  ],\n",
       "       [ 1840.3385 ],\n",
       "       [ 3618.1465 ],\n",
       "       [ 7228.674  ],\n",
       "       [  950.147  ],\n",
       "       [  893.1838 ],\n",
       "       [  926.6915 ],\n",
       "       [ 3166.022  ],\n",
       "       [16750.018  ],\n",
       "       [ 4768.7104 ],\n",
       "       [ 7434.2505 ],\n",
       "       [16853.766  ],\n",
       "       [ 3740.6895 ],\n",
       "       [  568.21796],\n",
       "       [  885.9316 ],\n",
       "       [  984.2115 ],\n",
       "       [  781.5398 ],\n",
       "       [  618.8856 ],\n",
       "       [ 2605.421  ],\n",
       "       [ 4331.962  ],\n",
       "       [ 1108.5602 ],\n",
       "       [ 2649.446  ],\n",
       "       [ 6127.265  ],\n",
       "       [  922.67755],\n",
       "       [15255.097  ],\n",
       "       [  505.5962 ],\n",
       "       [  968.5736 ],\n",
       "       [ 8023.1064 ],\n",
       "       [  651.11707],\n",
       "       [ 7154.042  ],\n",
       "       [ 1258.4658 ],\n",
       "       [ 4963.4507 ],\n",
       "       [  631.4404 ],\n",
       "       [  895.43665],\n",
       "       [ 1041.4949 ],\n",
       "       [  926.5419 ],\n",
       "       [ 2913.0352 ],\n",
       "       [ 7486.0156 ],\n",
       "       [ 3837.6375 ],\n",
       "       [  660.6907 ],\n",
       "       [11380.248  ],\n",
       "       [10365.726  ],\n",
       "       [  947.942  ],\n",
       "       [ 9529.789  ],\n",
       "       [  618.2818 ],\n",
       "       [  843.35034],\n",
       "       [ 2628.2979 ],\n",
       "       [ 1965.8163 ],\n",
       "       [10589.909  ],\n",
       "       [  945.9716 ],\n",
       "       [ 8431.589  ],\n",
       "       [  576.1602 ],\n",
       "       [  828.8158 ],\n",
       "       [  883.4196 ],\n",
       "       [ 2016.2668 ],\n",
       "       [  781.6476 ],\n",
       "       [12552.826  ],\n",
       "       [ 5628.204  ],\n",
       "       [25489.086  ],\n",
       "       [ 1062.5103 ],\n",
       "       [  586.77185],\n",
       "       [  829.7905 ],\n",
       "       [ 3160.0596 ],\n",
       "       [  883.5726 ],\n",
       "       [ 3158.298  ],\n",
       "       [ 7011.7124 ],\n",
       "       [ 5836.566  ],\n",
       "       [ 1743.8486 ],\n",
       "       [  583.0725 ],\n",
       "       [  925.80774],\n",
       "       [  867.8685 ],\n",
       "       [12795.413  ],\n",
       "       [ 2136.1377 ],\n",
       "       [ 1559.0822 ],\n",
       "       [ 3623.998  ],\n",
       "       [ 3161.6511 ],\n",
       "       [ 2746.728  ],\n",
       "       [14197.395  ],\n",
       "       [  983.3857 ],\n",
       "       [ 5568.2773 ],\n",
       "       [ 3000.9343 ],\n",
       "       [ 1882.9178 ],\n",
       "       [ 4128.1978 ],\n",
       "       [15690.626  ],\n",
       "       [ 6312.685  ],\n",
       "       [  903.4868 ],\n",
       "       [ 4452.522  ],\n",
       "       [ 3900.498  ],\n",
       "       [ 7679.4697 ],\n",
       "       [ 1357.3955 ],\n",
       "       [ 1962.8942 ],\n",
       "       [ 1938.9625 ],\n",
       "       [ 5128.352  ],\n",
       "       [ 4678.153  ],\n",
       "       [12853.079  ],\n",
       "       [  445.5587 ],\n",
       "       [ 5642.1797 ],\n",
       "       [12887.321  ],\n",
       "       [  476.99597],\n",
       "       [  907.81165],\n",
       "       [  909.19965],\n",
       "       [ 4804.169  ],\n",
       "       [ 3666.415  ],\n",
       "       [ 7021.322  ],\n",
       "       [12338.634  ],\n",
       "       [  795.1969 ],\n",
       "       [ 4368.9194 ],\n",
       "       [ 1144.0571 ],\n",
       "       [ 2247.742  ],\n",
       "       [ 1002.4719 ],\n",
       "       [ 2313.3892 ],\n",
       "       [ 3069.2627 ],\n",
       "       [ 1640.946  ],\n",
       "       [15221.26   ],\n",
       "       [10806.446  ],\n",
       "       [  915.96405],\n",
       "       [ 6996.49   ],\n",
       "       [ 8490.67   ],\n",
       "       [ 7908.0415 ],\n",
       "       [ 3781.898  ],\n",
       "       [ 9838.654  ],\n",
       "       [  985.1508 ],\n",
       "       [11809.254  ],\n",
       "       [ 4206.696  ],\n",
       "       [ 1002.41345],\n",
       "       [ 1212.0571 ],\n",
       "       [ 3415.1152 ],\n",
       "       [ 9024.628  ],\n",
       "       [ 1673.2494 ],\n",
       "       [  900.72156],\n",
       "       [11564.249  ],\n",
       "       [  601.61694],\n",
       "       [26593.65   ],\n",
       "       [ 1261.9021 ],\n",
       "       [ 4965.485  ],\n",
       "       [ 1054.72   ],\n",
       "       [  794.53577],\n",
       "       [  968.7765 ],\n",
       "       [ 1736.6298 ],\n",
       "       [18241.006  ],\n",
       "       [ 3283.4702 ],\n",
       "       [ 9363.411  ],\n",
       "       [ 4715.233  ],\n",
       "       [10506.519  ],\n",
       "       [ 4498.2017 ],\n",
       "       [  971.3385 ],\n",
       "       [36482.1    ],\n",
       "       [ 1027.9241 ],\n",
       "       [  988.67145],\n",
       "       [ 1590.2985 ],\n",
       "       [ 1689.655  ],\n",
       "       [  975.81213],\n",
       "       [  639.41455],\n",
       "       [ 1461.9211 ],\n",
       "       [  510.19684],\n",
       "       [ 1217.499  ],\n",
       "       [  821.10364],\n",
       "       [ 1249.9631 ],\n",
       "       [ 1235.3264 ],\n",
       "       [ 1415.138  ],\n",
       "       [ 1561.8589 ],\n",
       "       [ 1117.7361 ],\n",
       "       [ 1139.3616 ],\n",
       "       [ 1588.9739 ],\n",
       "       [ 1820.4502 ],\n",
       "       [  849.2804 ],\n",
       "       [ 1032.2275 ],\n",
       "       [  791.7943 ],\n",
       "       [ 1815.8391 ],\n",
       "       [ 1803.7188 ],\n",
       "       [  672.17456],\n",
       "       [  732.80725],\n",
       "       [ 6082.1367 ],\n",
       "       [17156.887  ],\n",
       "       [23098.646  ],\n",
       "       [17289.486  ],\n",
       "       [18282.85   ],\n",
       "       [22927.498  ],\n",
       "       [11431.315  ],\n",
       "       [16089.444  ],\n",
       "       [20600.59   ],\n",
       "       [46367.67   ],\n",
       "       [20703.56   ],\n",
       "       [21408.553  ],\n",
       "       [19373.033  ],\n",
       "       [19668.598  ],\n",
       "       [14332.552  ],\n",
       "       [21155.078  ],\n",
       "       [27067.469  ],\n",
       "       [ 1035.0042 ],\n",
       "       [11967.26   ],\n",
       "       [17604.611  ],\n",
       "       [18360.701  ],\n",
       "       [13788.284  ],\n",
       "       [14771.044  ],\n",
       "       [ 1237.386  ],\n",
       "       [14162.274  ],\n",
       "       [10091.34   ],\n",
       "       [23238.486  ],\n",
       "       [18289.94   ],\n",
       "       [17188.986  ],\n",
       "       [15158.639  ],\n",
       "       [ 6462.986  ],\n",
       "       [21124.94   ],\n",
       "       [ 7535.362  ],\n",
       "       [15860.126  ],\n",
       "       [ 1188.4841 ],\n",
       "       [24702.541  ],\n",
       "       [17990.662  ],\n",
       "       [16537.74   ],\n",
       "       [ 4571.428  ],\n",
       "       [ 9010.681  ],\n",
       "       [20799.322  ],\n",
       "       [11166.442  ],\n",
       "       [ 5934.754  ],\n",
       "       [13219.494  ],\n",
       "       [11308.509  ],\n",
       "       [ 1094.6722 ],\n",
       "       [34980.59   ],\n",
       "       [21616.508  ],\n",
       "       [17846.049  ],\n",
       "       [41981.195  ],\n",
       "       [14501.38   ],\n",
       "       [13348.366  ],\n",
       "       [ 9395.6045 ],\n",
       "       [19596.846  ],\n",
       "       [40016.344  ],\n",
       "       [11616.28   ],\n",
       "       [21923.225  ],\n",
       "       [ 6686.426  ],\n",
       "       [17266.553  ],\n",
       "       [ 5738.453  ],\n",
       "       [ 4424.1543 ],\n",
       "       [ 9692.776  ],\n",
       "       [17823.537  ],\n",
       "       [ 5106.988  ],\n",
       "       [ 6145.     ],\n",
       "       [16418.299  ],\n",
       "       [ 5800.8535 ],\n",
       "       [27943.334  ],\n",
       "       [13169.536  ],\n",
       "       [12552.248  ],\n",
       "       [36482.1    ],\n",
       "       [32596.44   ],\n",
       "       [31659.92   ],\n",
       "       [22140.6    ],\n",
       "       [40860.4    ],\n",
       "       [ 6123.537  ],\n",
       "       [18551.893  ],\n",
       "       [18311.166  ],\n",
       "       [18995.475  ],\n",
       "       [13987.846  ],\n",
       "       [ 3967.7026 ],\n",
       "       [16410.72   ],\n",
       "       [12094.577  ],\n",
       "       [ 6082.1367 ],\n",
       "       [17156.887  ],\n",
       "       [23098.646  ],\n",
       "       [17289.486  ],\n",
       "       [18282.85   ],\n",
       "       [22927.498  ],\n",
       "       [11431.315  ],\n",
       "       [16089.445  ],\n",
       "       [20600.59   ],\n",
       "       [21155.078  ],\n",
       "       [14332.552  ],\n",
       "       [ 4704.684  ],\n",
       "       [31142.145  ],\n",
       "       [ 1035.0042 ],\n",
       "       [11967.26   ],\n",
       "       [17604.611  ],\n",
       "       [18360.701  ],\n",
       "       [13788.284  ],\n",
       "       [29617.479  ],\n",
       "       [10414.463  ],\n",
       "       [13105.31   ],\n",
       "       [18896.338  ],\n",
       "       [11239.228  ],\n",
       "       [24398.375  ],\n",
       "       [10815.246  ],\n",
       "       [33464.027  ],\n",
       "       [ 1237.386  ],\n",
       "       [18289.94   ],\n",
       "       [20799.322  ],\n",
       "       [11166.442  ],\n",
       "       [13676.529  ],\n",
       "       [46367.67   ],\n",
       "       [21464.373  ],\n",
       "       [22572.01   ],\n",
       "       [ 1094.6722 ],\n",
       "       [ 4571.428  ],\n",
       "       [16346.637  ],\n",
       "       [31167.14   ],\n",
       "       [18321.26   ],\n",
       "       [19373.033  ],\n",
       "       [16098.074  ],\n",
       "       [20703.56   ],\n",
       "       [21408.553  ],\n",
       "       [19668.598  ],\n",
       "       [27067.469  ],\n",
       "       [14771.044  ],\n",
       "       [14162.274  ],\n",
       "       [10091.342  ],\n",
       "       [23238.482  ],\n",
       "       [17188.986  ],\n",
       "       [15158.639  ],\n",
       "       [ 6462.986  ],\n",
       "       [21124.94   ],\n",
       "       [ 7535.362  ],\n",
       "       [15860.126  ],\n",
       "       [ 1188.4841 ],\n",
       "       [24702.541  ],\n",
       "       [17990.662  ],\n",
       "       [16537.74   ],\n",
       "       [ 9010.681  ],\n",
       "       [ 5934.754  ],\n",
       "       [13219.494  ],\n",
       "       [11308.509  ],\n",
       "       [34980.59   ],\n",
       "       [21616.508  ],\n",
       "       [17846.049  ],\n",
       "       [41981.195  ],\n",
       "       [14501.38   ],\n",
       "       [13348.366  ],\n",
       "       [ 9395.6045 ],\n",
       "       [19596.846  ],\n",
       "       [40016.344  ],\n",
       "       [11616.28   ],\n",
       "       [21923.225  ],\n",
       "       [ 6686.426  ],\n",
       "       [17266.553  ],\n",
       "       [ 5738.453  ],\n",
       "       [ 4424.1543 ],\n",
       "       [ 9692.776  ],\n",
       "       [17823.537  ],\n",
       "       [ 5106.988  ],\n",
       "       [ 6145.     ],\n",
       "       [16418.299  ],\n",
       "       [ 5800.8535 ],\n",
       "       [27943.334  ],\n",
       "       [13169.536  ],\n",
       "       [12552.248  ],\n",
       "       [23822.396  ],\n",
       "       [10431.61   ],\n",
       "       [17882.842  ],\n",
       "       [28288.58   ],\n",
       "       [19157.033  ],\n",
       "       [ 5576.9204 ],\n",
       "       [ 8993.348  ],\n",
       "       [47894.84   ],\n",
       "       [ 5208.8794 ],\n",
       "       [25826.678  ],\n",
       "       [ 9860.831  ],\n",
       "       [15893.866  ],\n",
       "       [14036.781  ],\n",
       "       [ 4813.4507 ],\n",
       "       [20016.406  ],\n",
       "       [24348.852  ],\n",
       "       [19410.582  ],\n",
       "       [ 5795.8755 ],\n",
       "       [10772.163  ],\n",
       "       [20293.998  ],\n",
       "       [27660.92   ],\n",
       "       [ 1071.6335 ],\n",
       "       [14808.6045 ],\n",
       "       [ 5985.0586 ],\n",
       "       [ 3182.4287 ],\n",
       "       [30046.244  ],\n",
       "       [12396.866  ],\n",
       "       [16282.05   ],\n",
       "       [34851.51   ],\n",
       "       [18157.729  ],\n",
       "       [ 5000.6733 ],\n",
       "       [ 1733.2927 ],\n",
       "       [18091.932  ],\n",
       "       [15174.192  ],\n",
       "       [16698.908  ],\n",
       "       [12542.024  ],\n",
       "       [19637.938  ],\n",
       "       [10696.797  ],\n",
       "       [29533.463  ],\n",
       "       [  908.29846],\n",
       "       [ 8099.686  ],\n",
       "       [11627.458  ],\n",
       "       [12387.104  ],\n",
       "       [15105.845  ],\n",
       "       [ 4817.2095 ],\n",
       "       [22126.979  ],\n",
       "       [15933.74   ],\n",
       "       [21595.287  ],\n",
       "       [15027.161  ],\n",
       "       [12592.323  ],\n",
       "       [ 1309.6399 ],\n",
       "       [19240.354  ],\n",
       "       [ 1552.6794 ],\n",
       "       [17846.898  ],\n",
       "       [ 1359.113  ],\n",
       "       [ 3537.33   ],\n",
       "       [24668.6    ],\n",
       "       [  829.4261 ],\n",
       "       [ 9693.304  ],\n",
       "       [19130.396  ],\n",
       "       [49753.105  ],\n",
       "       [13204.333  ],\n",
       "       [ 1486.2595 ],\n",
       "       [15495.851  ],\n",
       "       [12415.585  ],\n",
       "       [ 1174.0457 ],\n",
       "       [18552.998  ],\n",
       "       [ 1088.731  ],\n",
       "       [ 5448.6504 ],\n",
       "       [ 1483.6516 ],\n",
       "       [ 6542.331  ],\n",
       "       [ 1282.2662 ],\n",
       "       [18558.518  ],\n",
       "       [11760.106  ],\n",
       "       [ 1296.8723 ],\n",
       "       [10073.663  ],\n",
       "       [10208.492  ],\n",
       "       [  929.41754],\n",
       "       [15277.175  ],\n",
       "       [ 9714.967  ],\n",
       "       [ 1253.4755 ],\n",
       "       [22391.057  ],\n",
       "       [14172.423  ]], dtype=float32)"
      ]
     },
     "execution_count": 481,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fin_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_final['Claps']=fin_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results=test_set_final[['Claps']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Claps</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37030.414062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37543.906250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1062.038574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30858.166016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8540.032227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>14927.567383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>9494.291992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>1228.931763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>21876.552734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>13848.422852</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>514 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Claps\n",
       "index              \n",
       "0      37030.414062\n",
       "1      37543.906250\n",
       "2       1062.038574\n",
       "3      30858.166016\n",
       "4       8540.032227\n",
       "...             ...\n",
       "509    14927.567383\n",
       "510     9494.291992\n",
       "511     1228.931763\n",
       "512    21876.552734\n",
       "513    13848.422852\n",
       "\n",
       "[514 rows x 1 columns]"
      ]
     },
     "execution_count": 453,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Indexing values to fit format\n",
    "final_results['index']=range(len(final_results))\n",
    "final_results=final_results.set_index(final_results['index'],drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results=final_results.drop(columns='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results.to_csv(\"Final_Results_Coskun_Mahmut.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These is the end of project. During the project we specifically used codes from __Tutorials of Advanced Data Analytics for Management Support Class__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
